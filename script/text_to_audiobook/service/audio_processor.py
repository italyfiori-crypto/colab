#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘å¤„ç†æœåŠ¡ - ç»Ÿä¸€çš„éŸ³é¢‘ç”Ÿæˆå’Œå‹ç¼©åŠŸèƒ½
"""

import os
import json
import numpy as np
from typing import List, Tuple, Optional, Dict
from dataclasses import dataclass
from infra import FileManager
from infra.config_loader import AppConfig
from util import OUTPUT_DIRECTORIES
from .edge_tts_processor import EdgeTTSProcessor

# éŸ³é¢‘å¤„ç†ä¾èµ–
try:
    import torch
    import soundfile as sf
    from kokoro import KPipeline
    AUDIO_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ éŸ³é¢‘ä¾èµ–ä¸å¯ç”¨: {e}")
    AUDIO_AVAILABLE = False


@dataclass
class AudioProcessingConfig:
    """éŸ³é¢‘å¤„ç†é…ç½®"""
    voice: str = ""
    speed: float = 0
    sample_rate: int = 24000
    audio_format: str = "wav"
    subtitle_format: str = "jsonl"


class AudioProcessor:
    """ç»Ÿä¸€çš„éŸ³é¢‘å¤„ç†å™¨"""
    
    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨
        
        Args:
            config: åº”ç”¨é…ç½®
        """
        self.config = config
        self.file_manager = FileManager()
        self.audio_config = AudioProcessingConfig()
        
        # åˆå§‹åŒ–Edge TTSå¤„ç†å™¨
        self.edge_tts_processor = EdgeTTSProcessor(config)
        
        # åˆå§‹åŒ–Kokoro TTS
        if AUDIO_AVAILABLE:
            try:
                self.tts_pipeline = KPipeline(lang_code='a')  # 'a' for American English
                print("âœ… Kokoro TTSç®¡é“åŠ è½½æˆåŠŸ")
            except Exception as e:
                print(f"âŒ Kokoro TTSç®¡é“åˆå§‹åŒ–å¤±è´¥: {e}")
                self.tts_pipeline = None
        else:
            self.tts_pipeline = None
            print("âš ï¸ éŸ³é¢‘ä¾èµ–ä¸å¯ç”¨ï¼ŒéŸ³é¢‘åŠŸèƒ½å°†è¢«è·³è¿‡")
    
    def generate_audio_files(self, sentence_files: List[str], output_dir: str, voice: str, speed: float) -> Tuple[List[str], List[str]]:
        """
        ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        
        Args:
            sentence_files: å¥å­æ–‡ä»¶åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            voice: å£°éŸ³ç±»å‹
            speed: è¯­é€Ÿ
            
        Returns:
            (éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨, å­—å¹•æ–‡ä»¶åˆ—è¡¨)
        """
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨Edge TTS
        if self.edge_tts_processor.should_use_edge_tts(voice):
            print(f"ğŸ”Š ä½¿ç”¨Edge TTSè¿›è¡ŒéŸ³é¢‘ç”Ÿæˆï¼Œè¯­éŸ³: {voice}")
            return self.edge_tts_processor.generate_audio_files(sentence_files, output_dir, voice, speed)
        
        # ä½¿ç”¨åŸæœ‰çš„Kokoro TTSé€»è¾‘
        if not self.tts_pipeline:
            print(f"ğŸ”Š TTSç®¡é“ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘ç”Ÿæˆ")
            return [], []
        
        if not sentence_files:
            print(f"âš ï¸ æœªæ‰¾åˆ°å¥å­æ–‡ä»¶ï¼Œè·³è¿‡éŸ³é¢‘ç”Ÿæˆ")
            return [], []
        
        # æ›´æ–°é…ç½®
        self.audio_config.voice = voice
        self.audio_config.speed = speed
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        audio_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['audio'])
        subtitle_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['subtitles'])
        self.file_manager.create_directory(audio_dir)
        self.file_manager.create_directory(subtitle_dir)
        
        print(f"ğŸ”Š å¼€å§‹éŸ³é¢‘ç”Ÿæˆï¼Œå…± {len(sentence_files)} ä¸ªæ–‡ä»¶...")
        
        audio_files = []
        subtitle_files = []
        
        for i, sentence_file in enumerate(sentence_files, 1):
            try:
                filename = os.path.basename(sentence_file)
                print(f"ğŸ”Š ç”ŸæˆéŸ³é¢‘ ({i}/{len(sentence_files)}): {filename}")
                
                # å¤„ç†å•ä¸ªæ–‡ä»¶
                audio_file, subtitle_file = self._process_file(sentence_file, audio_dir, subtitle_dir)
                if audio_file:
                    audio_files.append(audio_file)
                if subtitle_file:
                    subtitle_files.append(subtitle_file)
                
            except Exception as e:
                print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥ {filename}: {e}")
                continue
        
        print(f"\nâœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆ! ç”Ÿæˆ {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶å’Œ {len(subtitle_files)} ä¸ªå­—å¹•æ–‡ä»¶")
        return audio_files, subtitle_files
    
    def _process_file(self, sentence_file: str, audio_dir: str, subtitle_dir: str) -> Tuple[Optional[str], Optional[str]]:
        """
        å¤„ç†å•ä¸ªå¥å­æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼‰ï¼Œç”Ÿæˆå¯¹åº”çš„éŸ³é¢‘å’Œå­—å¹•
        
        Args:
            sentence_file: å¥å­æ–‡ä»¶è·¯å¾„ï¼ˆJSONLæ ¼å¼ï¼‰
            audio_dir: éŸ³é¢‘è¾“å‡ºç›®å½•
            subtitle_dir: å­—å¹•è¾“å‡ºç›®å½•
            
        Returns:
            (éŸ³é¢‘æ–‡ä»¶è·¯å¾„, å­—å¹•æ–‡ä»¶è·¯å¾„)
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§å¹¶æå–å¥å­
            is_complete, segments_data = self._check_file_completeness(sentence_file)
            
            if not is_complete:
                print(f"âš ï¸ æ–‡ä»¶æ‹†åˆ†ç¿»è¯‘ä¸å®Œæ•´ï¼Œè·³è¿‡: {os.path.basename(sentence_file)}")
                return None, None
            
            if not segments_data:
                print(f"âš ï¸ æ–‡ä»¶æ— æœ‰æ•ˆå¥å­ç‰‡æ®µ: {os.path.basename(sentence_file)}")
                return None, None
                
        except Exception as e:
            print(f"âš ï¸ æ–‡ä»¶è§£æå¤±è´¥: {os.path.basename(sentence_file)}, é”™è¯¯: {e}")
            return None, None
        
        # æå–è‹±æ–‡å¥å­ç”¨äºéŸ³é¢‘ç”Ÿæˆ
        english_sentences = [seg['original'] for seg in segments_data]
        
        # ç”Ÿæˆæ–‡ä»¶å
        base_name = self.file_manager.get_basename_without_extension(sentence_file)
        audio_file = os.path.join(audio_dir, f"{base_name}.{self.audio_config.audio_format}")
        subtitle_file = os.path.join(subtitle_dir, f"{base_name}.{self.audio_config.subtitle_format}")

        if os.path.exists(audio_file) and os.path.exists(subtitle_file):
            print(f"ğŸ”Š éŸ³é¢‘æ–‡ä»¶å’Œå­—å¹•æ–‡ä»¶å·²ç»å­˜åœ¨, è·³è¿‡å¤„ç†")
            return audio_file, subtitle_file

        # ä¸ºæ¯ä¸ªå¥å­å•ç‹¬ç”ŸæˆéŸ³é¢‘å¹¶è·å–çœŸå®æ—¶é•¿
        temp_audio_files, durations = self._generate_individual_audios(english_sentences, base_name, audio_dir)
        
        if temp_audio_files and durations:
            # å°†å•å¥éŸ³é¢‘åˆå¹¶ä¸ºå®Œæ•´éŸ³é¢‘æ–‡ä»¶
            if self._merge_audio_files(temp_audio_files, audio_file):
                # ä½¿ç”¨çœŸå®æ—¶é•¿ç”ŸæˆåŒè¯­å­—å¹•æ–‡ä»¶
                self._generate_bilingual_subtitle_file(segments_data, durations, subtitle_file)
                return audio_file, subtitle_file
            else:
                print(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {base_name}")
                return None, None
        else:
            print(f"âŒ å•å¥éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {base_name}")
            return None, None
    
    def _generate_individual_audios(self, sentences: List[str], base_name: str, audio_dir: str) -> Tuple[List[str], List[float]]:
        """
        ä¸ºæ¯ä¸ªå¥å­å•ç‹¬ç”ŸæˆéŸ³é¢‘æ–‡ä»¶
        
        Args:
            sentences: å¥å­åˆ—è¡¨
            base_name: åŸºç¡€æ–‡ä»¶å
            audio_dir: éŸ³é¢‘è¾“å‡ºç›®å½•
            
        Returns:
            (éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨, å¯¹åº”çš„æ—¶é•¿åˆ—è¡¨)
        """
        audio_files = []
        durations = []
        
        for i, sentence in enumerate(sentences):
            # ç”Ÿæˆä¸´æ—¶éŸ³é¢‘æ–‡ä»¶å
            temp_audio_file = os.path.join(audio_dir, f"{base_name}_temp_{i:03d}.{self.audio_config.audio_format}")
            
            try:
                # ç”Ÿæˆå•å¥éŸ³é¢‘
                if self._generate_sentence_audio(sentence, temp_audio_file):
                    # è·å–å®é™…æ—¶é•¿
                    duration = self._get_audio_duration(temp_audio_file)
                    if duration > 0:
                        audio_files.append(temp_audio_file)
                        durations.append(duration)
                    else:
                        print(f"âš ï¸ å¥å­éŸ³é¢‘æ—¶é•¿ä¸º0: {sentence[:30]}...")
                        # å¦‚æœè·å–æ—¶é•¿å¤±è´¥ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_audio_file):
                            os.remove(temp_audio_file)
                else:
                    print(f"âš ï¸ å¥å­éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {sentence[:30]}...")
                    
            except Exception as e:
                print(f"âŒ å¤„ç†å¥å­å¤±è´¥ [{i}]: {e}")
                # æ¸…ç†å¯èƒ½åˆ›å»ºçš„ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_audio_file):
                    os.remove(temp_audio_file)
                continue
        
        return audio_files, durations
    
    def _generate_sentence_audio(self, text: str, output_path: str) -> bool:
        """
        ç”Ÿæˆå•ä¸ªå¥å­çš„éŸ³é¢‘
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ç”ŸæˆæˆåŠŸ
        """
        try:
            # ä½¿ç”¨Kokoroç®¡é“ç”ŸæˆéŸ³é¢‘
            generator = self.tts_pipeline(text, voice=self.audio_config.voice, speed=self.audio_config.speed)
            audio_chunks = []
            
            for (_, _, audio_chunk) in generator:
                if isinstance(audio_chunk, torch.Tensor):
                    audio_chunk = audio_chunk.cpu().numpy()
                audio_chunks.append(audio_chunk)
            
            if not audio_chunks:
                print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {text[:50]}...")
                return False
            
            # åˆå¹¶éŸ³é¢‘å—å¹¶ä¿å­˜
            audio = np.concatenate(audio_chunks)
            sf.write(output_path, audio, self.audio_config.sample_rate)
            return True
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
            return False
    
    def _get_audio_duration(self, audio_path: str) -> float:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            # ä½¿ç”¨soundfileè·å–éŸ³é¢‘ä¿¡æ¯
            info = sf.info(audio_path)
            return info.duration
        except Exception as e:
            print(f"âŒ è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0
    
    def _merge_audio_files(self, audio_files: List[str], output_path: str) -> bool:
        """
        å°†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´çš„éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_files: è¦åˆå¹¶çš„éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆå¹¶æ˜¯å¦æˆåŠŸ
        """
        if not audio_files:
            return False
        
        try:
            # è¯»å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
            audio_chunks = []
            for audio_file in audio_files:
                audio_data, sample_rate = sf.read(audio_file)
                # ç¡®ä¿é‡‡æ ·ç‡ä¸€è‡´
                if sample_rate != self.audio_config.sample_rate:
                    print(f"âš ï¸ é‡‡æ ·ç‡ä¸åŒ¹é…: {audio_file} ({sample_rate} vs {self.audio_config.sample_rate})")
                audio_chunks.append(audio_data)
            
            # åˆå¹¶éŸ³é¢‘æ•°æ®
            if audio_chunks:
                merged_audio = np.concatenate(audio_chunks)
                sf.write(output_path, merged_audio, self.audio_config.sample_rate)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in audio_files:
                    try:
                        os.remove(temp_file)
                    except Exception as e:
                        print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
                
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {e}")
            return False
    
    def _generate_subtitle_file(self, sentences: List[str], durations: List[float], output_path: str):
        """
        ç”Ÿæˆå­—å¹•æ–‡ä»¶ï¼ˆSRTæ ¼å¼ï¼‰
        
        Args:
            sentences: å¥å­åˆ—è¡¨
            durations: æ¯ä¸ªå¥å­å¯¹åº”çš„çœŸå®æ—¶é•¿åˆ—è¡¨
            output_path: è¾“å‡ºå­—å¹•æ–‡ä»¶è·¯å¾„
        """
        if not sentences or not durations:
            return
        
        # ç¡®ä¿å¥å­å’Œæ—¶é•¿åˆ—è¡¨é•¿åº¦åŒ¹é…
        if len(sentences) != len(durations):
            print(f"âš ï¸ å¥å­æ•°é‡({len(sentences)})ä¸æ—¶é•¿æ•°é‡({len(durations)})ä¸åŒ¹é…")
            return
        
        srt_content = []
        current_time = 0.0
        
        for i, (sentence, duration) in enumerate(zip(sentences, durations), 1):
            start_time = current_time
            end_time = current_time + duration
            
            # æ ¼å¼åŒ–æ—¶é—´æˆ³
            start_timestamp = self._format_timestamp(start_time)
            end_timestamp = self._format_timestamp(end_time)
            
            # æ·»åŠ å­—å¹•æ¡ç›®
            srt_content.append(f"{i}")
            srt_content.append(f"{start_timestamp} --> {end_timestamp}")
            srt_content.append(sentence)
            srt_content.append("")  # ç©ºè¡Œåˆ†éš”
            
            current_time = end_time
        
        # å†™å…¥æ–‡ä»¶
        self.file_manager.write_text_file(output_path, '\n'.join(srt_content))
    
    def _format_timestamp(self, seconds: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸º SRT æ ¼å¼ (HH:MM:SS,mmm)
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            æ ¼å¼åŒ–çš„æ—¶é—´æˆ³
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"
    
    def compress_audio_files(self, audio_files: List[str], output_dir: str) -> bool:
        """
        å‹ç¼©éŸ³é¢‘æ–‡ä»¶ï¼ˆWAVè½¬MP3ï¼‰
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æ˜¯å¦å‹ç¼©æˆåŠŸ
        """
        if not audio_files:
            print(f"âš ï¸ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡å‹ç¼©")
            return True
        
        try:
            # å°è¯•å¯¼å…¥pydubè¿›è¡ŒéŸ³é¢‘å‹ç¼©
            from pydub import AudioSegment
            
            # åˆ›å»ºå‹ç¼©éŸ³é¢‘ç›®å½•
            compressed_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['compressed_audio'])
            self.file_manager.create_directory(compressed_dir)
            
            print(f"ğŸ—œï¸ å¼€å§‹éŸ³é¢‘å‹ç¼©ï¼Œå…± {len(audio_files)} ä¸ªæ–‡ä»¶...")
            
            success_count = 0
            for i, audio_file in enumerate(audio_files, 1):
                try:
                    filename = os.path.basename(audio_file)
                    base_name = self.file_manager.get_basename_without_extension(filename)
                    output_file = os.path.join(compressed_dir, f"{base_name}.mp3")
                    
                    # åŠ è½½WAVæ–‡ä»¶å¹¶è½¬æ¢ä¸ºMP3
                    audio = AudioSegment.from_wav(audio_file)
                    audio.export(output_file, format="mp3", bitrate="64k")
                    
                    success_count += 1
                    print(f"ğŸ—œï¸ å‹ç¼©å®Œæˆ ({i}/{len(audio_files)}): {filename}")
                    
                except Exception as e:
                    print(f"âŒ å‹ç¼©å¤±è´¥ {filename}: {e}")
                    continue
            
            print(f"\nâœ… éŸ³é¢‘å‹ç¼©å®Œæˆ! æˆåŠŸå‹ç¼© {success_count}/{len(audio_files)} ä¸ªæ–‡ä»¶")
            return success_count > 0
            
        except ImportError:
            print(f"âš ï¸ pydubåº“ä¸å¯ç”¨ï¼Œè·³è¿‡éŸ³é¢‘å‹ç¼©")
            return True
        except Exception as e:
            print(f"âŒ éŸ³é¢‘å‹ç¼©å¤±è´¥: {e}")
            return False
    
    def _check_file_completeness(self, sentence_file: str) -> Tuple[bool, List[Dict[str, str]]]:
        """
        æ£€æŸ¥JSONLæ–‡ä»¶çš„å®Œæ•´æ€§å¹¶æå–å¥å­ç‰‡æ®µ
        
        Args:
            sentence_file: JSONLå¥å­æ–‡ä»¶è·¯å¾„
            
        Returns:
            (æ˜¯å¦å®Œæ•´, å¥å­ç‰‡æ®µåˆ—è¡¨)
        """
        try:
            segments_data = []
            all_paragraphs_success = True
            
            with open(sentence_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        paragraph_data = json.loads(line)
                        
                        # æ£€æŸ¥å¿…éœ€å­—æ®µ
                        if not isinstance(paragraph_data, dict):
                            continue
                        
                        # æ£€æŸ¥successçŠ¶æ€
                        if not paragraph_data.get('success', False):
                            all_paragraphs_success = False
                            break
                        
                        # æå–segments
                        segments = paragraph_data.get('segments', [])
                        if segments:
                            for segment in segments:
                                if isinstance(segment, dict) and 'original' in segment and 'translation' in segment:
                                    segments_data.append({
                                        'original': segment['original'].strip(),
                                        'translation': segment['translation'].strip()
                                    })
                                    
                    except json.JSONDecodeError as e:
                        print(f"      âš ï¸ JSONè§£æå¤±è´¥ è¡Œ{line_num}: {e}")
                        all_paragraphs_success = False
                        break
            
            return all_paragraphs_success, segments_data
            
        except Exception as e:
            print(f"      âŒ æ–‡ä»¶è¯»å–å¼‚å¸¸: {e}")
            return False, []
    
    def _generate_bilingual_subtitle_file(self, segments_data: List[Dict[str, str]], durations: List[float], subtitle_file: str):
        """
        ç”ŸæˆåŒè¯­å­—å¹•æ–‡ä»¶ï¼ˆJSONLæ ¼å¼ï¼‰
        
        Args:
            segments_data: å¥å­ç‰‡æ®µæ•°æ® [{"original": "è‹±æ–‡", "translation": "ä¸­æ–‡"}, ...]
            durations: æ¯ä¸ªå¥å­çš„éŸ³é¢‘æ—¶é•¿åˆ—è¡¨
            subtitle_file: å­—å¹•æ–‡ä»¶è·¯å¾„
        """
        try:
            import json
            
            with open(subtitle_file, 'w', encoding='utf-8') as f:
                current_time = 0.0
                
                for i, (segment, duration) in enumerate(zip(segments_data, durations), 1):
                    # è®¡ç®—æ—¶é—´æˆ³
                    start_time = current_time
                    end_time = current_time + duration
                    current_time = end_time
                    
                    # æ ¼å¼åŒ–æ—¶é—´æˆ³
                    start_timestamp = self._format_timestamp(start_time)
                    end_timestamp = self._format_timestamp(end_time)
                    timestamp = f"{start_timestamp} --> {end_timestamp}"
                    
                    # æ„å»ºJSONLæ¡ç›®
                    entry = {
                        "index": i,
                        "timestamp": timestamp,
                        "english_text": segment['original'],
                        "chinese_text": segment['translation']
                    }
                    
                    # å†™å…¥JSONLæ¡ç›®
                    f.write(json.dumps(entry, ensure_ascii=False, separators=(',', ':')) + '\n')
                    
        except Exception as e:
            print(f"âŒ ç”ŸæˆåŒè¯­å­—å¹•æ–‡ä»¶å¤±è´¥: {e}")
    
    def _format_timestamp(self, seconds: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼
        
        Args:
            seconds: ç§’æ•°
            
        Returns:
            SRTæ ¼å¼æ—¶é—´æˆ³
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    