#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯æ±‡æœåŠ¡ - ç»Ÿä¸€çš„è¯æ±‡å¤„ç†åŠŸèƒ½
å®Œå…¨åŸºäºmodulesç›®å½•é€»è¾‘å®ç°ï¼Œæ•´åˆè¯æ±‡æå–ã€ç®¡ç†å’Œå¯ŒåŒ–åŠŸèƒ½
"""

import os
import json
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass
from infra import FileManager
from infra.config_loader import AppConfig
from util import OUTPUT_DIRECTORIES

# å¯¼å…¥å†…éƒ¨æ¨¡å—
from ._word_extractor import WordExtractor, WordExtractionConfig
from ._vocabulary_enricher import VocabularyEnricher, VocabularyEnricherConfig


@dataclass
class VocabularyManagerConfig:
    """è¯æ±‡ç®¡ç†å™¨é…ç½®"""
    
    # é»˜è®¤è·¯å¾„é…ç½®
    default_master_vocab_path: str = "vocabulary/master_vocabulary.json"
    
    # å­æ¨¡å—é…ç½®
    extraction: WordExtractionConfig = None
    enrichment: VocabularyEnricherConfig = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–é»˜è®¤å€¼"""
        if self.extraction is None:
            self.extraction = WordExtractionConfig()
        if self.enrichment is None:
            self.enrichment = VocabularyEnricherConfig()


class VocabularyService:
    """ç»Ÿä¸€çš„è¯æ±‡æœåŠ¡ - å®Œå…¨åŸºäºmodules/vocabulary_manager.pyå®ç°"""
    
    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ–è¯æ±‡æœåŠ¡
        
        Args:
            config: åº”ç”¨é…ç½®
        """
        self.config = config
        self.file_manager = FileManager()
        
        # åˆå§‹åŒ–é…ç½®ï¼ˆæŒ‰modules/vocabulary_manager.pyçš„é€»è¾‘ï¼‰
        self.vocab_config = VocabularyManagerConfig()
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.extractor = WordExtractor(self.vocab_config.extraction)
        self.enricher = VocabularyEnricher(self.vocab_config.enrichment)
        
        print("ğŸ“š è¯æ±‡æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def process_vocabulary(self, sentence_files: List[str], output_dir: str, book_name: str, master_vocab_path: str) -> Tuple[List[str], bool]:
        """
        å¤„ç†è¯æ±‡æå–å’Œåˆ†çº§ - å®Œå…¨æŒ‰ç…§modules/vocabulary_manager.pyçš„process_book_vocabularyé€»è¾‘
        
        Args:
            sentence_files: å¥å­æ–‡ä»¶åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            book_name: ä¹¦ç±åç§°
            master_vocab_path: ä¸»è¯æ±‡è¡¨è·¯å¾„
            
        Returns:
            (ç« èŠ‚è¯æ±‡æ–‡ä»¶åˆ—è¡¨, æ˜¯å¦æˆåŠŸ)
        """
        if not sentence_files:
            print("âš ï¸ æœªæ‰¾åˆ°å¥å­æ–‡ä»¶ï¼Œè·³è¿‡è¯æ±‡å¤„ç†")
            return [], True
        
        try:
            # ä½¿ç”¨é»˜è®¤æˆ–æŒ‡å®šçš„æ€»è¯æ±‡è¡¨è·¯å¾„
            print(f"ğŸ“– ä½¿ç”¨æ€»è¯æ±‡è¡¨: {master_vocab_path}")
            
            # ç¬¬ä¸€æ­¥ï¼šæå–å­ç« èŠ‚è¯æ±‡ï¼ˆæå–æ‰€æœ‰å•è¯ï¼‰
            print(f"\nğŸ”„ ç¬¬1æ­¥: ä» {len(sentence_files)} ä¸ªå¥å­æ–‡ä»¶ä¸­æå–è¯æ±‡...")
            subchapter_vocab_files, all_words = self.extractor.extract_subchapter_words(
                sentence_files, output_dir, master_vocab_path
            )
                    
            if not all_words:
                print("âœ… æ²¡æœ‰æ–°è¯æ±‡éœ€è¦å¤„ç†")
                return subchapter_vocab_files, True
            
            # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ECDICTè¡¥å……åŸºç¡€ä¿¡æ¯
            print(f"\nğŸ”„ ç¬¬2æ­¥: ä½¿ç”¨ECDICTä¸º {len(all_words)} ä¸ªæ–°è¯æ±‡è¡¥å……åŸºç¡€ä¿¡æ¯...")
            success = self.enricher.enrich_vocabulary_with_ecdict(all_words, master_vocab_path)
            
            if not success:
                print(f"âš ï¸ ECDICTåŸºç¡€ä¿¡æ¯è¡¥å……å¤±è´¥")
                return subchapter_vocab_files, False
            
            # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨APIè¡¥å……éŸ³é¢‘ä¿¡æ¯
            print(f"\nğŸ”„ ç¬¬3æ­¥: ä¸ºè¯æ±‡è¡¥å……éŸ³é¢‘ä¿¡æ¯...")
            audio_success = self.enricher.enrich_vocabulary_with_cambridge(master_vocab_path)
            
            if not audio_success:
                print(f"âš ï¸ éŸ³é¢‘ä¿¡æ¯è¡¥å……è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†åŸºç¡€ä¿¡æ¯å·²ä¿å­˜")
            
            # ç¬¬å››æ­¥ï¼šæ›´æ–°ç« èŠ‚è¯æ±‡æ–‡ä»¶ä¸ºè¯¦ç»†æ ¼å¼ï¼ˆä¿æŒåŸæ–‡é¡ºåºï¼‰
            print(f"\nğŸ”„ ç¬¬4æ­¥: æ›´æ–°ç« èŠ‚è¯æ±‡æ–‡ä»¶ä¸ºè¯¦ç»†æ ¼å¼...")
            update_success = self.extractor.update_vocabulary_info(output_dir, master_vocab_path)
            
            if update_success:
                print(f"âœ… è¯æ±‡å¤„ç†å®Œæˆ!")
                print(f"ğŸ“„ å­ç« èŠ‚è¯æ±‡æ–‡ä»¶: {len(subchapter_vocab_files)} ä¸ª")
                print(f"ğŸ“š æ€»è¯æ±‡è¡¨: {master_vocab_path}")
            else:
                print(f"âš ï¸ ç« èŠ‚è¯æ±‡æ–‡ä»¶æ ¼å¼æ›´æ–°å¤±è´¥")
            
            return subchapter_vocab_files, True
            
        except Exception as e:
            print(f"âŒ è¯æ±‡å¤„ç†å¤±è´¥: {e}")
            return [], False
    
    def get_existing_vocabulary_files(self, output_dir: str) -> List[str]:
        """
        è·å–å·²å­˜åœ¨çš„è¯æ±‡æ–‡ä»¶
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            è¯æ±‡æ–‡ä»¶åˆ—è¡¨
        """
        vocab_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['vocabulary'])
        return self.file_manager.get_files_by_extension(vocab_dir, ".json")
    
    def get_vocabulary_stats(self, master_vocab_path: str) -> Dict:
        """è·å–è¯æ±‡ç»Ÿè®¡ä¿¡æ¯ - å®Œå…¨æŒ‰ç…§modules/vocabulary_manager.pyçš„é€»è¾‘"""
        if not os.path.exists(master_vocab_path):
            return {}
        
        try:
            with open(master_vocab_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                metadata = data.get("metadata", {})
                # ç¡®ä¿è¿”å›çš„ç»Ÿè®¡æ•°æ®æ˜¯æœ€æ–°çš„æ ¼å¼
                if 'level_distribution' in metadata:
                    # å¦‚æœæ˜¯æ—§æ ¼å¼çš„level_distributionï¼Œè½¬æ¢ä¸ºæ ‡ç­¾æ ¼å¼
                    level_dist = metadata['level_distribution']
                    if any(key.isdigit() or 'çº§' in key or 'Level' in key for key in level_dist.keys()):
                        # æ—§æ ¼å¼ï¼Œè¿”å›ç©ºçš„æ ‡ç­¾åˆ†å¸ƒ
                        metadata['level_distribution'] = {}
                return metadata
        except Exception as e:
            print(f"âš ï¸ è·å–è¯æ±‡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}