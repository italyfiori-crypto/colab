#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡æœ¬å¤„ç†æœåŠ¡ - ç»Ÿä¸€çš„æ–‡æœ¬æ‹†åˆ†åŠŸèƒ½
åˆå¹¶ç« èŠ‚æ‹†åˆ†ã€å­ç« èŠ‚æ‹†åˆ†ã€å¥å­æ‹†åˆ†
"""

import os
import re
import math
from typing import List, Tuple
from infra import AIClient, FileManager
from infra.config_loader import AppConfig, ChapterPattern
from util import OUTPUT_DIRECTORIES, generate_chapter_filename, generate_sub_filename, clean_title_for_filename, get_basename_without_extension


class TextProcessor:
    """ç»Ÿä¸€çš„æ–‡æœ¬å¤„ç†å™¨"""
    
    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ–æ–‡æœ¬å¤„ç†å™¨
        
        Args:
            config: åº”ç”¨é…ç½®
        """
        self.config = config
        self.ai_client = AIClient(config.api)
        self.file_manager = FileManager()
    
    def split_book_to_sentences(self, input_file: str, output_dir: str) -> Tuple[List[str], List[str], List[str]]:
        """
        å®Œæ•´çš„ä¹¦ç±æ‹†åˆ†æµç¨‹ï¼šç« èŠ‚ â†’ å­ç« èŠ‚ â†’ å¥å­
        
        Args:
            input_file: è¾“å…¥ä¹¦ç±æ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            (ç« èŠ‚æ–‡ä»¶åˆ—è¡¨, å­ç« èŠ‚æ–‡ä»¶åˆ—è¡¨, å¥å­æ–‡ä»¶åˆ—è¡¨)
        """
        # 1. ç« èŠ‚æ‹†åˆ†
        chapter_files = self._split_chapters(input_file, output_dir)
        
        # 2. å­ç« èŠ‚æ‹†åˆ†
        sub_chapter_files = self._split_sub_chapters(chapter_files, output_dir)
        
        # 3. å¥å­æ‹†åˆ†
        sentence_files = self._split_sentences(sub_chapter_files, output_dir)
        
        return chapter_files, sub_chapter_files, sentence_files
    
    def _split_chapters(self, input_file: str, output_dir: str) -> List[str]:
        """
        ç« èŠ‚æ‹†åˆ†
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            ç« èŠ‚æ–‡ä»¶åˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹ç« èŠ‚æ‹†åˆ†...")
        
        # è¯»å–è¾“å…¥æ–‡ä»¶
        content = self.file_manager.read_text_file(input_file)
        
        # åˆ›å»ºç« èŠ‚ç›®å½•
        chapters_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['chapters'])
        self.file_manager.create_directory(chapters_dir)
        
        # å°è¯•å„ç§ç« èŠ‚æ¨¡å¼
        for pattern in self.config.chapter_patterns:
            chapters = self._extract_chapters_with_pattern(content, pattern)
            if chapters:
                print(f"âœ… ä½¿ç”¨æ¨¡å¼ '{pattern.name}' æ‰¾åˆ° {len(chapters)} ä¸ªç« èŠ‚")
                break
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç« èŠ‚ï¼Œå°†æ•´ä¸ªæ–‡ä»¶ä½œä¸ºä¸€ä¸ªç« èŠ‚
            book_name = self.file_manager.get_basename_without_extension(input_file)
            chapters = [(f"Chapter 1: {book_name}", content)]
            print(f"âš ï¸ æœªæ‰¾åˆ°ç« èŠ‚åˆ†éš”ç¬¦ï¼Œå°†æ•´ä¸ªæ–‡ä»¶ä½œä¸ºå•ä¸ªç« èŠ‚")
        
        # ä¿å­˜ç« èŠ‚æ–‡ä»¶
        chapter_files = []
        for i, (title, chapter_content) in enumerate(chapters, 1):
            # ä½¿ç”¨æ–°çš„å‘½åæ ¼å¼ï¼š001_Down_the_Rabbit-Hole.txt
            filename = generate_chapter_filename(i, title)
            chapter_file = os.path.join(chapters_dir, filename)
            
            # æ„å»ºç« èŠ‚å†…å®¹
            full_content = f"{title}\n\n{chapter_content.strip()}"
            self.file_manager.write_text_file(chapter_file, full_content)
            chapter_files.append(chapter_file)
            
            print(f"ğŸ“ å·²ä¿å­˜ç« èŠ‚: {filename}")
        
        print(f"âœ… ç« èŠ‚æ‹†åˆ†å®Œæˆ! å…±ç”Ÿæˆ {len(chapter_files)} ä¸ªç« èŠ‚æ–‡ä»¶")
        return chapter_files
    
    def _extract_chapters_with_pattern(self, content: str, pattern: ChapterPattern) -> List[Tuple[str, str]]:
        """
        ä½¿ç”¨æŒ‡å®šæ¨¡å¼æå–ç« èŠ‚
        
        Args:
            content: æ–‡æœ¬å†…å®¹
            pattern: ç« èŠ‚æ¨¡å¼
            
        Returns:
            ç« èŠ‚åˆ—è¡¨ [(æ ‡é¢˜, å†…å®¹), ...]
        """
        flags = re.MULTILINE | re.DOTALL
        if self.config.ignore_case:
            flags |= re.IGNORECASE
        
        matches = list(re.finditer(pattern.multiline_regex, content, flags))
        if not matches:
            return []
        
        chapters = []
        for i, match in enumerate(matches):
            # æå–æ ‡é¢˜
            match_lines = match.group(0).split('\n')
            if pattern.title_line_index < len(match_lines):
                title = match_lines[pattern.title_line_index].strip()
            else:
                title = f"Chapter {i + 1}"
            
            # ç¡®å®šå†…å®¹èŒƒå›´
            content_start = match.end()
            if i + 1 < len(matches):
                content_end = matches[i + 1].start()
            else:
                content_end = len(content)
            
            chapter_content = content[content_start:content_end].strip()
            if chapter_content:
                chapters.append((title, chapter_content))
        
        return chapters
    
    def _split_sub_chapters(self, chapter_files: List[str], output_dir: str) -> List[str]:
        """
        å­ç« èŠ‚æ‹†åˆ†
        
        Args:
            chapter_files: ç« èŠ‚æ–‡ä»¶åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å­ç« èŠ‚æ–‡ä»¶åˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹å­ç« èŠ‚æ‹†åˆ†...")
        
        # åˆ›å»ºå­ç« èŠ‚ç›®å½•
        sub_chapters_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['sub_chapters'])
        self.file_manager.create_directory(sub_chapters_dir)
        
        sub_chapter_files = []
        config = self.config.text_processing
        
        for chapter_file in chapter_files:
            content = self.file_manager.read_text_file(chapter_file)
            title, body = self.file_manager.extract_title_and_body(content)
            
            # æŒ‰æ®µè½åˆ†å‰²
            paragraphs = [p.strip() for p in re.split(r'\n\n+', body) if p.strip()]
            
            if not paragraphs:
                continue
            
            # è®¡ç®—æ¯ä¸ªå­ç« èŠ‚çš„ç›®æ ‡è¯æ•°
            total_words = sum(len(p.split()) for p in paragraphs)
            max_words = config.sub_chapter_max_minutes * config.words_per_minute
            
            if total_words <= max_words:
                # æ•´ä¸ªç« èŠ‚ä½œä¸ºä¸€ä¸ªå­ç« èŠ‚
                sub_chapter_content = f"{title}\n\n{body}"
                chapter_basename = os.path.basename(chapter_file)
                sub_filename = generate_sub_filename(chapter_basename, 1)
                sub_file = os.path.join(sub_chapters_dir, sub_filename)
                self.file_manager.write_text_file(sub_file, sub_chapter_content)
                sub_chapter_files.append(sub_file)
            else:
                # æ‹†åˆ†ä¸ºå¤šä¸ªå­ç« èŠ‚
                current_words = 0
                current_paragraphs = []
                sub_index = 1
                
                for paragraph in paragraphs:
                    paragraph_words = len(paragraph.split())
                    
                    if current_words + paragraph_words > max_words and current_paragraphs:
                        # ä¿å­˜å½“å‰å­ç« èŠ‚
                        sub_content = f"{title} (Part {sub_index})\n\n" + '\n\n'.join(current_paragraphs)
                        chapter_basename = os.path.basename(chapter_file)
                        sub_filename = generate_sub_filename(chapter_basename, sub_index)
                        sub_file = os.path.join(sub_chapters_dir, sub_filename)
                        self.file_manager.write_text_file(sub_file, sub_content)
                        sub_chapter_files.append(sub_file)
                        
                        # é‡ç½®
                        current_paragraphs = [paragraph]
                        current_words = paragraph_words
                        sub_index += 1
                    else:
                        current_paragraphs.append(paragraph)
                        current_words += paragraph_words
                
                # ä¿å­˜æœ€åä¸€ä¸ªå­ç« èŠ‚
                if current_paragraphs:
                    sub_content = f"{title} (Part {sub_index})\n\n" + '\n\n'.join(current_paragraphs)
                    chapter_basename = os.path.basename(chapter_file)
                    sub_filename = generate_sub_filename(chapter_basename, sub_index)
                    sub_file = os.path.join(sub_chapters_dir, sub_filename)
                    self.file_manager.write_text_file(sub_file, sub_content)
                    sub_chapter_files.append(sub_file)
        
        print(f"âœ… å­ç« èŠ‚æ‹†åˆ†å®Œæˆ! ç”Ÿæˆ {len(sub_chapter_files)} ä¸ªå­ç« èŠ‚æ–‡ä»¶")
        return sub_chapter_files
    
    def _split_sentences(self, sub_chapter_files: List[str], output_dir: str) -> List[str]:
        """
        å¥å­æ‹†åˆ†
        
        Args:
            sub_chapter_files: å­ç« èŠ‚æ–‡ä»¶åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¥å­æ–‡ä»¶åˆ—è¡¨
        """
        print(f"ğŸ”„ å¼€å§‹AIå¥å­æ‹†åˆ†...")
        
        # åˆ›å»ºå¥å­ç›®å½•
        sentences_dir = os.path.join(output_dir, OUTPUT_DIRECTORIES['sentences'])
        self.file_manager.create_directory(sentences_dir)
        
        sentence_files = []
        
        for sub_chapter_file in sub_chapter_files:
            content = self.file_manager.read_text_file(sub_chapter_file)
            title, body = self.file_manager.extract_title_and_body(content)
            
            # å¤„ç†æ®µè½å¥å­æ‹†åˆ†
            processed_content = self._split_paragraphs_to_sentences(body)
            
            # æ„å»ºæœ€ç»ˆå†…å®¹
            final_content = f"{title}\n\n{processed_content}"
            
            # ä¿å­˜å¥å­æ–‡ä»¶
            filename = os.path.basename(sub_chapter_file)
            sentence_file = os.path.join(sentences_dir, filename)
            self.file_manager.write_text_file(sentence_file, final_content)
            sentence_files.append(sentence_file)
            
            print(f"ğŸ“ å·²å¤„ç†å¥å­æ‹†åˆ†: {filename}")
        
        print(f"âœ… å¥å­æ‹†åˆ†å®Œæˆ! æœ€ç»ˆç”Ÿæˆ {len(sentence_files)} ä¸ªå¥å­æ–‡ä»¶")
        return sentence_files
    
    def _split_paragraphs_to_sentences(self, content: str) -> str:
        """
        å°†æ®µè½æ‹†åˆ†ä¸ºå¥å­
        
        Args:
            content: æ®µè½å†…å®¹
            
        Returns:
            æ‹†åˆ†åçš„å†…å®¹
        """
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in re.split(r'\n\n', content) if p.strip()]
        
        processed_paragraphs = []
        
        for paragraph in paragraphs:
            # å¯¹æ®µè½è¿›è¡Œå¥å­æ‹†åˆ†
            sentences = self._split_paragraph_sentences(paragraph)
            
            if sentences:
                paragraph_content = '\n'.join(sentences)
                processed_paragraphs.append(paragraph_content)
        
        return '\n\n'.join(processed_paragraphs)
    
    def _split_paragraph_sentences(self, paragraph: str) -> List[str]:
        """
        ä½¿ç”¨AIæ‹†åˆ†æ®µè½ä¸­çš„å¥å­
        
        Args:
            paragraph: æ®µè½æ–‡æœ¬
            
        Returns:
            å¥å­åˆ—è¡¨
        """
        # æ¸…ç†æ–‡æœ¬
        text = re.sub(r'\s+', ' ', paragraph.strip())
        if not text:
            return []
        
        # ç®€å•çš„åŸºç¡€å¥å­åˆ†å‰²
        sentences = re.split(r'[.!?]+\s+', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # ä½¿ç”¨AIæ™ºèƒ½æ‹†åˆ†é•¿å¥
        result = []
        config = self.config.text_processing
        
        for i, sentence in enumerate(sentences):
            if len(sentence) < config.ai_split_threshold:
                result.append(sentence)
            else:
                # è·å–ä¸Šä¸‹æ–‡
                context_sentences = self._get_context_sentences(sentences, i, config.context_window)
                split_result = self._ai_split_sentence(sentence, context_sentences, paragraph)
                result.extend(split_result)
        
        return result
    
    def _get_context_sentences(self, sentences: List[str], current_index: int, window_size: int) -> List[str]:
        """è·å–å½“å‰å¥å­çš„ä¸Šä¸‹æ–‡"""
        start = max(0, current_index - window_size)
        end = min(len(sentences), current_index + window_size + 1)
        return sentences[start:end]
    
    def _ai_split_sentence(self, sentence: str, context_sentences: List[str], paragraph_context: str) -> List[str]:
        """
        ä½¿ç”¨AIæ‹†åˆ†å•ä¸ªå¥å­
        
        Args:
            sentence: è¦æ‹†åˆ†çš„å¥å­
            context_sentences: ä¸Šä¸‹æ–‡å¥å­
            paragraph_context: æ®µè½ä¸Šä¸‹æ–‡
            
        Returns:
            æ‹†åˆ†åçš„å¥å­åˆ—è¡¨
        """
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = ""
        if context_sentences:
            context_info = f"ä¸Šä¸‹æ–‡å¥å­ï¼š\n{chr(10).join(context_sentences)}\n\n"
        
        if paragraph_context:
            context_info += f"æ®µè½èƒŒæ™¯ï¼š{paragraph_context[:200]}...\n\n"
        
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡é•¿å¥æ‹†åˆ†ä¸ºå¤šä¸ªè¯­ä¹‰å®Œæ•´çš„å­å¥ã€‚æ‹†åˆ†æ—¶éœ€è¦è€ƒè™‘ï¼š
1. ä¿æŒæ¯ä¸ªå­å¥çš„è¯­ä¹‰å®Œæ•´æ€§
2. è€ƒè™‘è¯­æ³•ç»“æ„å’Œé€»è¾‘å…³ç³»
3. å­å¥é•¿åº¦é€‚ä¸­ï¼ˆå»ºè®®20-60å­—ç¬¦ï¼‰
4. ä¿æŒåŸæ„ä¸å˜

{context_info}éœ€è¦æ‹†åˆ†çš„å¥å­ï¼š
{sentence}

è¯·ç›´æ¥è¿”å›æ‹†åˆ†åçš„å­å¥ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦æ·»åŠ åºå·æˆ–å…¶ä»–æ ¼å¼ï¼š"""

        try:
            response = self.ai_client.chat_completion(prompt)
            if not response:
                raise RuntimeError("AIè¿”å›ç©ºç»“æœ")
            
            # è§£ææ‹†åˆ†ç»“æœ
            split_sentences = []
            for line in response.split('\n'):
                line = line.strip()
                if line and not line.startswith('*') and not line.startswith('-'):
                    # æ¸…ç†å¯èƒ½çš„åºå·
                    line = re.sub(r'^\d+\.\s*', '', line)
                    line = re.sub(r'^[â€¢Â·]\s*', '', line)
                    if line:
                        split_sentences.append(line)
            
            if not split_sentences:
                raise RuntimeError("AIæ‹†åˆ†è¿”å›ç©ºç»“æœ")
            
            return split_sentences
            
        except Exception as e:
            print(f"âŒ AIæ‹†åˆ†å¤±è´¥: {e}")
            raise