#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¥å­æ‹†åˆ†æ¨¡å—
ä½¿ç”¨AIæ™ºèƒ½æ‹†åˆ†é•¿å¥ä¸ºè¯­ä¹‰å®Œæ•´çš„å­å¥
"""

import os
import re
import requests
from typing import List
from dataclasses import dataclass



@dataclass
class SentenceSplitterConfig:
    """AIå¥å­æ‹†åˆ†é…ç½®ç±»"""
    
    # è¾“å‡ºå­ç›®å½•å
    output_subdir: str = "sentences"
    
    # AIæ‹†åˆ†é…ç½®
    ai_split_threshold: int = 80  # è§¦å‘AIæ‹†åˆ†çš„å¥å­é•¿åº¦é˜ˆå€¼
    api_key: str = ""
    model: str = "deepseek-ai/DeepSeek-V2.5"
    base_url: str = "https://api.siliconflow.cn/v1"
    timeout: int = 30
    context_window_size: int = 2  # æä¾›ç»™AIçš„ä¸Šä¸‹æ–‡å¥å­æ•°é‡


class AISmartSplitter:
    """AIæ™ºèƒ½å¥å­æ‹†åˆ†å™¨"""
    
    def __init__(self, config: SentenceSplitterConfig):
        """
        åˆå§‹åŒ–AIæ‹†åˆ†å™¨
        
        Args:
            config: å¥å­æ‹†åˆ†é…ç½®
        """
        self.config = config
        
        if not config.api_key:
            raise RuntimeError("AIæ‹†åˆ†å™¨åˆå§‹åŒ–å¤±è´¥: ç¼ºå°‘APIå¯†é’¥")
    
    def split_with_ai(self, sentences: List[str], paragraph_context: str = "") -> List[str]:
        """
        ä½¿ç”¨AIæ™ºèƒ½æ‹†åˆ†å¥å­åˆ—è¡¨
        
        Args:
            sentences: åŸå§‹å¥å­åˆ—è¡¨
            paragraph_context: æ®µè½ä¸Šä¸‹æ–‡
            
        Returns:
            æ‹†åˆ†åçš„å¥å­åˆ—è¡¨
        """
        result = []
        
        for i, sentence in enumerate(sentences):
            if len(sentence) < self.config.ai_split_threshold:
                # çŸ­å¥ç›´æ¥ä¿ç•™
                result.append(sentence)
            else:
                # é•¿å¥ä½¿ç”¨AIæ‹†åˆ†
                context_sentences = self._get_context_sentences(sentences, i)
                split_result = self._ai_split_sentence(sentence, context_sentences, paragraph_context)
                result.extend(split_result)
        
        return result
    
    def _get_context_sentences(self, sentences: List[str], current_index: int) -> List[str]:
        """è·å–å½“å‰å¥å­çš„ä¸Šä¸‹æ–‡å¥å­"""
        start = max(0, current_index - self.config.context_window_size)
        end = min(len(sentences), current_index + self.config.context_window_size + 1)
        return sentences[start:end]
    
    def _ai_split_sentence(self, sentence: str, context_sentences: List[str], paragraph_context: str) -> List[str]:
        """
        ä½¿ç”¨AIæ‹†åˆ†å•ä¸ªå¥å­
        
        Args:
            sentence: è¦æ‹†åˆ†çš„å¥å­
            context_sentences: ä¸Šä¸‹æ–‡å¥å­
            paragraph_context: æ®µè½ä¸Šä¸‹æ–‡
            
        Returns:
            æ‹†åˆ†åçš„å¥å­åˆ—è¡¨
        """
        try:
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = ""
            if context_sentences:
                context_info = f"ä¸Šä¸‹æ–‡å¥å­ï¼š\n{chr(10).join(context_sentences)}\n\n"
            
            if paragraph_context:
                context_info += f"æ®µè½èƒŒæ™¯ï¼š{paragraph_context[:200]}...\n\n"
            
            prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡é•¿å¥æ‹†åˆ†ä¸ºå¤šä¸ªè¯­ä¹‰å®Œæ•´çš„å­å¥ã€‚æ‹†åˆ†æ—¶éœ€è¦è€ƒè™‘ï¼š
1. ä¿æŒæ¯ä¸ªå­å¥çš„è¯­ä¹‰å®Œæ•´æ€§
2. è€ƒè™‘è¯­æ³•ç»“æ„å’Œé€»è¾‘å…³ç³»
3. å­å¥é•¿åº¦é€‚ä¸­ï¼ˆå»ºè®®20-60å­—ç¬¦ï¼‰
4. ä¿æŒåŸæ„ä¸å˜

{context_info}éœ€è¦æ‹†åˆ†çš„å¥å­ï¼š
{sentence}

è¯·ç›´æ¥è¿”å›æ‹†åˆ†åçš„å­å¥ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦æ·»åŠ åºå·æˆ–å…¶ä»–æ ¼å¼ï¼š"""

            response = self._call_api(prompt)
            if not response:
                return [sentence]
            
            result_text = response.strip()
            
            # è§£ææ‹†åˆ†ç»“æœ
            split_sentences = []
            for line in result_text.split('\n'):
                line = line.strip()
                if line and not line.startswith('*') and not line.startswith('-'):
                    # æ¸…ç†å¯èƒ½çš„åºå·
                    line = re.sub(r'^\d+\.\s*', '', line)
                    line = re.sub(r'^[â€¢Â·]\s*', '', line)
                    if line:
                        split_sentences.append(line)
            
            # å¦‚æœAIæ‹†åˆ†å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if not split_sentences:
                raise RuntimeError(f"AIæ‹†åˆ†è¿”å›ç©ºç»“æœ: {sentence}")
            
            return split_sentences
            
        except Exception as e:
            print(f"âŒ AIæ‹†åˆ†å¤±è´¥: {e}")
            raise
    
    def _call_api(self, prompt: str) -> str:
        """
        è°ƒç”¨SiliconFlow API
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            
        Returns:
            APIå“åº”å†…å®¹
        """
        try:
            headers = {
                'Authorization': f'Bearer {self.config.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.config.model,
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'temperature': 0.1,
                'max_tokens': 1000
            }
            
            response = requests.post(
                f"{self.config.base_url}/chat/completions",
                headers=headers,
                json=data,
                timeout=self.config.timeout
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                print(f"âš ï¸ APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                return ""
                
        except Exception as e:
            print(f"âš ï¸ APIè°ƒç”¨å¼‚å¸¸: {e}")
            return ""


class SentenceSplitter:
    """å¥å­æ‹†åˆ†å™¨"""
    
    def __init__(self, config: SentenceSplitterConfig):
        """
        åˆå§‹åŒ–AIå¥å­æ‹†åˆ†å™¨
        
        Args:
            config: å¥å­æ‹†åˆ†é…ç½®
        """
        self.config = config
        self.ai_splitter = AISmartSplitter(config)
    
    def split_files(self, input_files: List[str], output_dir: str) -> List[str]:
        """
        æ‹†åˆ†æ–‡ä»¶åˆ—è¡¨ä¸ºå¥å­çº§æ–‡ä»¶
        
        Args:
            input_files: è¾“å…¥æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            ç”Ÿæˆçš„å¥å­æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        sentences_dir = os.path.join(output_dir, self.config.output_subdir)
        os.makedirs(sentences_dir, exist_ok=True)
        
        output_files = []
        
        for input_file in input_files:
            try:
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
                filename = os.path.basename(input_file)
                output_file = os.path.join(sentences_dir, filename)
                
                # å¤„ç†å•ä¸ªæ–‡ä»¶
                self._process_file(input_file, output_file)
                output_files.append(output_file)
                
                print(f"ğŸ“ å·²å¤„ç†å¥å­æ‹†åˆ†: {filename}")
            except Exception as e:
                print(f"âŒ æ‹†åˆ†å¤±è´¥: {e}")
                continue
        
        print(f"\nğŸ“ å¥å­æ‹†åˆ†å®Œæˆï¼Œè¾“å‡ºåˆ°: {sentences_dir}")
        return output_files
    
    def _process_file(self, input_file: str, output_file: str):
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶çš„å¥å­æ‹†åˆ†
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå–æ ‡é¢˜å’Œæ­£æ–‡
        title, body = self._extract_title_and_body(content)
        
        # å¤„ç†æ®µè½å¥å­æ‹†åˆ†
        processed_content = self._split_paragraphs_to_sentences(body)
        
        # æ„å»ºæœ€ç»ˆå†…å®¹
        final_content = f"{title}\n\n{processed_content}"
        
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(final_content)
    
    def _extract_title_and_body(self, content: str) -> tuple[str, str]:
        """
        æå–æ ‡é¢˜å’Œæ­£æ–‡å†…å®¹
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            
        Returns:
            (æ ‡é¢˜, æ­£æ–‡å†…å®¹)
        """
        lines = content.split('\n')
        
        # ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜
        title = lines[0].strip() if lines else "Unknown Title"
        
        # å…¶ä½™æ˜¯æ­£æ–‡ï¼ˆå»é™¤å¼€å¤´çš„ç©ºè¡Œï¼‰
        body_lines = lines[1:]
        while body_lines and not body_lines[0].strip():
            body_lines.pop(0)
        
        body = '\n'.join(body_lines)
        return title, body
    
    def _split_paragraphs_to_sentences(self, content: str) -> str:
        """
        å°†å†…å®¹æŒ‰æ®µè½æ‹†åˆ†ï¼Œå†å°†æ¯ä¸ªæ®µè½æ‹†åˆ†ä¸ºå¥å­
        
        Args:
            content: æ­£æ–‡å†…å®¹
            
        Returns:
            å¤„ç†åçš„å†…å®¹
        """
        # æŒ‰æ®µè½åˆ†å‰²ï¼ˆåŒæ¢è¡Œåˆ†å‰²ï¼‰
        paragraphs = re.split(r'\n\n', content)
        
        # è¿‡æ»¤ç©ºæ®µè½
        paragraphs = [p.strip() for p in paragraphs if p.strip()]
        
        processed_paragraphs = []
        
        for paragraph in paragraphs:
            # å¯¹æ®µè½è¿›è¡Œå¥å­æ‹†åˆ†
            sentences = self._split_sentences(paragraph, paragraph_context=paragraph)
            
            # å°†å¥å­åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆæ¯å¥ä¸€è¡Œï¼‰
            if sentences:
                paragraph_content = '\n'.join(sentences)
                processed_paragraphs.append(paragraph_content)
        
        # æ®µè½é—´ç”¨ç©ºè¡Œåˆ†éš”
        return '\n\n'.join(processed_paragraphs)
    
    def _split_sentences(self, text: str, paragraph_context: str = "") -> List[str]:
        """
        ä½¿ç”¨AIæ™ºèƒ½æ‹†åˆ†æ–‡æœ¬ä¸ºå¥å­
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            paragraph_context: æ®µè½ä¸Šä¸‹æ–‡
            
        Returns:
            å¥å­åˆ—è¡¨
        """
        # æ¸…ç†æ–‡æœ¬ï¼ˆç§»é™¤å¤šä½™ç©ºç™½ï¼‰
        text = re.sub(r'\s+', ' ', text.strip())
        
        if not text:
            return []
        
        # ç®€å•çš„åŸºç¡€å¥å­åˆ†å‰²ï¼ˆæŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å‰²ï¼‰
        sentences = re.split(r'[.!?]+\s+', text)
        # è¿‡æ»¤ç©ºå¥å­
        sentences = [s.strip() for s in sentences if s.strip()]
        
        # ä½¿ç”¨AIæ™ºèƒ½æ‹†åˆ†
        sentences = self.ai_splitter.split_with_ai(sentences, paragraph_context)
        
        # æ¸…ç†å¥å­ï¼ˆå»é™¤é¦–å°¾ç©ºç™½ï¼‰
        sentences = [s.strip() for s in sentences if s.strip()]
        
        return sentences
