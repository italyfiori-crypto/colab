#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯æ±‡ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å•è¯æå–å’Œå¯ŒåŒ–æµç¨‹
"""

import os
import json
from typing import List, Dict, Tuple
from dataclasses import dataclass
from pathlib import Path

from .word_extractor import WordExtractor, WordExtractionConfig
from .vocabulary_enricher import VocabularyEnricher, VocabularyEnricherConfig, load_master_vocabulary

@dataclass
class VocabularyManagerConfig:
    """è¯æ±‡ç®¡ç†å™¨é…ç½®"""
    
    # é»˜è®¤è·¯å¾„é…ç½®
    default_master_vocab_path: str = "vocabulary/master_vocabulary.json"
    
    # å­æ¨¡å—é…ç½®
    extraction: WordExtractionConfig = None
    enrichment: VocabularyEnricherConfig = None
    
    def __post_init__(self):
        """åˆå§‹åŒ–é»˜è®¤å€¼"""
        if self.extraction is None:
            self.extraction = WordExtractionConfig()
        if self.enrichment is None:
            self.enrichment = VocabularyEnricherConfig()


class VocabularyManager:
    """è¯æ±‡ç®¡ç†å™¨ - ç»Ÿä¸€å¤„ç†å•è¯æå–ã€å¯ŒåŒ–å’Œå­˜å‚¨"""
    
    def __init__(self, config: VocabularyManagerConfig):
        """
        åˆå§‹åŒ–è¯æ±‡ç®¡ç†å™¨
        
        Args:
            config: ç®¡ç†å™¨é…ç½®
        """
        self.config = config
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.extractor = WordExtractor(self.config.extraction)
        self.enricher = VocabularyEnricher(self.config.enrichment)
        
        print("ğŸ“š è¯æ±‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_book_vocabulary(self, sentence_files: List[str], output_dir: str, 
                              book_name: str, master_vocab_path: str = None) -> List[str]:
        """
        å¤„ç†ä¹¦ç±è¯æ±‡ - å®Œæ•´æµç¨‹ï¼ˆä»¥å­ç« èŠ‚ä¸ºå•ä½ï¼‰
        
        Args:
            sentence_files: å¥å­æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            book_name: ä¹¦ç±åç§°
            master_vocab_path: æ€»è¯æ±‡è¡¨è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç”Ÿæˆçš„å­ç« èŠ‚è¯æ±‡æ–‡ä»¶åˆ—è¡¨
        """
        # ä½¿ç”¨é»˜è®¤æˆ–æŒ‡å®šçš„æ€»è¯æ±‡è¡¨è·¯å¾„
        print(f"ğŸ“– ä½¿ç”¨æ€»è¯æ±‡è¡¨: {master_vocab_path}")
        
        # ç¬¬ä¸€æ­¥ï¼šæå–å­ç« èŠ‚è¯æ±‡ï¼ˆæå–æ‰€æœ‰å•è¯ï¼‰
        print(f"\nğŸ”„ ç¬¬1æ­¥: ä» {len(sentence_files)} ä¸ªå¥å­æ–‡ä»¶ä¸­æå–è¯æ±‡...")
        subchapter_vocab_files, all_words = self.extractor.extract_subchapter_words(
            sentence_files, output_dir, master_vocab_path
        )
        
        # åŠ è½½ç°æœ‰æ€»è¯æ±‡è¡¨ï¼Œåˆ¤æ–­å“ªäº›æ˜¯æ–°è¯
        existing_vocab = load_master_vocabulary(master_vocab_path)
        new_words = [word for word in all_words if word not in existing_vocab]
        
        if not new_words:
            print("âœ… æ‰€æœ‰è¯æ±‡éƒ½å·²å­˜åœ¨äºæ€»è¯æ±‡è¡¨ä¸­ï¼Œè·³è¿‡å¯ŒåŒ–æ­¥éª¤")
            return subchapter_vocab_files
        
        # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨ECDICTè¡¥å……åŸºç¡€ä¿¡æ¯
        print(f"\nğŸ”„ ç¬¬2æ­¥: ä½¿ç”¨ECDICTä¸º {len(new_words)} ä¸ªæ–°è¯æ±‡è¡¥å……åŸºç¡€ä¿¡æ¯...")
        success = self.enricher.enrich_vocabulary_with_ecdict(
            new_words, master_vocab_path
        )
        
        if not success:
            print(f"âš ï¸ ECDICTåŸºç¡€ä¿¡æ¯è¡¥å……å¤±è´¥")
            return subchapter_vocab_files
        
        # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨APIè¡¥å……éŸ³é¢‘ä¿¡æ¯
        print(f"\nğŸ”„ ç¬¬3æ­¥: ä¸ºè¯æ±‡è¡¥å……éŸ³é¢‘ä¿¡æ¯...")
        audio_success = self.enricher.enrich_vocabulary_with_cambridge(master_vocab_path)
        
        if audio_success:
            print(f"âœ… è¯æ±‡å¤„ç†å®Œæˆ!")
            print(f"ğŸ“„ å­ç« èŠ‚è¯æ±‡æ–‡ä»¶: {len(subchapter_vocab_files)} ä¸ª")
            print(f"ğŸ“š æ€»è¯æ±‡è¡¨: {master_vocab_path}")
        else:
            print(f"âš ï¸ éŸ³é¢‘ä¿¡æ¯è¡¥å……è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œä½†åŸºç¡€ä¿¡æ¯å·²ä¿å­˜")
        
        return subchapter_vocab_files
    
    def get_vocabulary_stats(self, master_vocab_path: str) -> Dict:
        """è·å–è¯æ±‡ç»Ÿè®¡ä¿¡æ¯"""
        if not os.path.exists(master_vocab_path):
            return {}
        
        try:
            with open(master_vocab_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                metadata = data.get("metadata", {})
                # ç¡®ä¿è¿”å›çš„ç»Ÿè®¡æ•°æ®æ˜¯æœ€æ–°çš„æ ¼å¼
                if 'level_distribution' in metadata:
                    # å¦‚æœæ˜¯æ—§æ ¼å¼çš„level_distributionï¼Œè½¬æ¢ä¸ºæ ‡ç­¾æ ¼å¼
                    level_dist = metadata['level_distribution']
                    if any(key.isdigit() or 'çº§' in key or 'Level' in key for key in level_dist.keys()):
                        # æ—§æ ¼å¼ï¼Œè¿”å›ç©ºçš„æ ‡ç­¾åˆ†å¸ƒ
                        metadata['level_distribution'] = {}
                return metadata
        except Exception as e:
            print(f"âš ï¸ è·å–è¯æ±‡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}