#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç« èŠ‚æ‹†åˆ†ä¸»ç¨‹åº - ç²¾ç®€ç‰ˆ
æ”¯æŒé…ç½®æ–‡ä»¶å’Œæœ€å°‘çš„å‘½ä»¤è¡Œå‚æ•°
"""

import argparse
import sys
import os
import time

from infra.config_loader import ConfigLoader
from service.workflow_executor import WorkflowExecutor
from util import OUTPUT_DIRECTORIES
from util.file_utils import find_txt_files


def process_single_file(input_file: str, args, config: dict, workflow: 'WorkflowExecutor') -> dict:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶
    
    Returns:
        åŒ…å«å¤„ç†ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    # é»˜è®¤ç›®å½•
    program_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    file_name = os.path.basename(input_file)
    output_dir = os.path.join(program_root, "output", os.path.splitext(file_name)[0])
    master_vocab_file = os.path.join(program_root, "output", "vocabulary", "master_vocabulary.json")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    try:
        os.makedirs(output_dir, exist_ok=True)
    except Exception as e:
        raise Exception(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")
    
    if args.verbose:
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {input_file}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    # è®°å½•æ–‡ä»¶å¤„ç†å¼€å§‹æ—¶é—´
    file_start_time = time.time()
    
    # æ‰§è¡Œå„ä¸ªå¤„ç†æµç¨‹
    sub_chapter_files, sentence_files = [], []
    chapter_time, sentence_time = 0, 0
    
    # ç« èŠ‚å’Œå­ç« èŠ‚æ‹†åˆ†
    if args.chapter:
        _, sub_chapter_files, chapter_time = workflow.execute_chapter_processing(input_file, output_dir, args.verbose)
    else:
        # è·å–å·²å­˜åœ¨çš„å­ç« èŠ‚æ–‡ä»¶
        from util.file_utils import get_existing_files
        sub_chapter_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['sub_chapters'], ".txt")
    
    # å¥å­æ‹†åˆ†
    if args.sentence:
        if not sub_chapter_files:
            raise Exception("æœªæ‰¾åˆ°å­ç« èŠ‚æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ --chapter è¿›è¡Œç« èŠ‚æ‹†åˆ†")
        sentence_files, sentence_time = workflow.execute_sentence_processing(sub_chapter_files, output_dir, args.verbose)
    else:
        # è·å–å·²å­˜åœ¨çš„å¥å­æ–‡ä»¶
        from util.file_utils import get_existing_files
        sentence_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['sentences'], ".txt")
    
    # éŸ³é¢‘ç”Ÿæˆ
    audio_files, subtitle_files, audio_time = [], [], 0
    if args.audio:
        audio_files, subtitle_files, audio_time = workflow.execute_audio_processing(sentence_files, output_dir, args.voice, args.speed, args.verbose)
    else:
        from util.file_utils import get_existing_files
        audio_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['audio'], ".wav")
        subtitle_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['subtitles'], ".srt")

    # å­—å¹•è§£æå’Œç¿»è¯‘
    parsed_files, parse_time = [], 0
    if args.parse:
        parsed_files, parse_time = workflow.execute_translation_and_analysis(subtitle_files, sub_chapter_files, audio_files, output_dir, args.verbose)

    # éŸ³é¢‘å‹ç¼©
    compressed_files, compression_time = [], 0
    if args.compress:
        if not audio_files:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ --audio è¿›è¡ŒéŸ³é¢‘ç”Ÿæˆ")
        else:
            compressed_files, compression_time = workflow.execute_audio_compression(audio_files, output_dir, args.verbose)

    # è¯æ±‡å¤„ç†
    chapter_vocab_files, vocabulary_time = [], 0
    if args.vocabulary:
        book_name = os.path.splitext(os.path.basename(input_file))[0]
        chapter_vocab_files, vocabulary_time = workflow.execute_vocabulary_processing(sentence_files, output_dir, book_name, master_vocab_file, args.verbose)
    
    # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
    statistics_time = 0
    if args.stats:
        # ç‹¬ç«‹æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
        _, statistics_time = workflow.execute_statistics_collection(sub_chapter_files, audio_files, output_dir, args.verbose)
    
    # è®¡ç®—è€—æ—¶
    total_time = chapter_time + sentence_time + audio_time + parse_time + compression_time + vocabulary_time + statistics_time
    file_total_time = time.time() - file_start_time
    
    return {
        'input_file': input_file,
        'output_dir': output_dir,
        'success': True,
        'times': {
            'chapter': chapter_time,
            'sentence': sentence_time,
            'audio': audio_time,
            'parse': parse_time,
            'compression': compression_time,
            'vocabulary': vocabulary_time,
            'statistics': statistics_time,
            'total': total_time,
            'file_total': file_total_time
        },
        'files': {
            'sentence_files': len(sentence_files),
            'audio_files': len(audio_files),
            'subtitle_files': len(subtitle_files),
            'compressed_files': len(compressed_files),
            'parsed_files': len(parsed_files),
            'chapter_vocab_files': len(chapter_vocab_files)
        }
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç« èŠ‚æ‹†åˆ†å·¥å…· - å°†ä¹¦ç±æ–‡æœ¬æ‹†åˆ†ä¸ºç‹¬ç«‹çš„ç« èŠ‚æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s data/greens.txt
  %(prog)s data/books/  # æ‰¹é‡å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰.txtæ–‡ä»¶
  %(prog)s data/book.txt --chapter --sentence
  %(prog)s data/book.txt --chapter --sentence --audio --parse --vocabulary
  %(prog)s data/book.txt --sentence --audio  # åªè¿è¡Œå¥å­æ‹†åˆ†å’ŒéŸ³é¢‘ç”Ÿæˆ
  %(prog)s data/book.txt --chapter  # åªè¿è¡Œç« èŠ‚æ‹†åˆ†
  
é»˜è®¤é…ç½®æ–‡ä»¶: text_to_audiobook/config.json
é»˜è®¤è¾“å‡ºç›®å½•: ./output
é»˜è®¤æ€»è¯æ±‡è¡¨: script/text_to_audiobook/vocabulary/master_vocabulary.json
è¾“å‡ºæ ¼å¼: chapters/, sub_chapters/, sentences/, audio/, subtitles/, vocabulary/ ç›®å½•
        """
    )
    
    # æ ¸å¿ƒå‚æ•°
    parser.add_argument('input_path',help='è¾“å…¥æ–‡æœ¬æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--verbose','-v',action='store_true',help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # æ–‡æœ¬æ‹†åˆ†å‚æ•°
    parser.add_argument('--chapter', action='store_true', help='å¯ç”¨ç« èŠ‚å’Œå­ç« èŠ‚æ‹†åˆ†')
    parser.add_argument('--sentence', action='store_true', help='å¯ç”¨å¥å­æ‹†åˆ†')

    # éŸ³é¢‘ç”Ÿæˆå‚æ•°
    parser.add_argument('--audio', action='store_true', help='å¯ç”¨éŸ³é¢‘ç”Ÿæˆ')
    parser.add_argument('--voice', default='af_bella', help='è¯­éŸ³æ¨¡å‹ (é»˜è®¤: af_bella)')
    parser.add_argument('--speed', type=float, default=0.8, help='è¯­éŸ³é€Ÿåº¦ (é»˜è®¤: 1.0)')
    
    # å­—å¹•è§£æå‚æ•°
    parser.add_argument('--parse', action='store_true', help='å¯ç”¨å­—å¹•è§£æ')
    
    # éŸ³é¢‘å‹ç¼©å‚æ•°
    parser.add_argument('--compress', action='store_true', help='å¯ç”¨éŸ³é¢‘å‹ç¼©')
    
    # è¯æ±‡å¤„ç†å‚æ•°
    parser.add_argument('--vocabulary', action='store_true', help='å¯ç”¨è¯æ±‡æå–å’Œåˆ†çº§')
    
    # ç»Ÿè®¡å‚æ•°
    parser.add_argument('--stats', action='store_true', help='å¯ç”¨ç»Ÿè®¡ä¿¡æ¯æ”¶é›†')
    args = parser.parse_args()

    # é…ç½®è·¯å¾„
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')

    # å‘ç°å¾…å¤„ç†çš„æ–‡ä»¶
    try:
        input_files = find_txt_files(args.input_path)
    except ValueError as e:
        print(f"é”™è¯¯: {e}")
        return 1
    
    # æ˜¾ç¤ºå‘ç°çš„æ–‡ä»¶
    print(f"ğŸ” å‘ç° {len(input_files)} ä¸ª .txt æ–‡ä»¶:")
    for i, file in enumerate(input_files, 1):
        print(f"  {i}. {os.path.basename(file)}")
    
    # è®°å½•ç¨‹åºå¼€å§‹æ—¶é—´
    program_start_time = time.time()
    
    try:
        # åŠ è½½é…ç½®
        if not os.path.exists(config_path):
            print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return 1
        
        config_loader = ConfigLoader()
        config = config_loader.load_config(config_path)
        if args.verbose:
            print(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        
        # åˆå§‹åŒ–å·¥ä½œæµæ‰§è¡Œå™¨
        workflow = WorkflowExecutor(config)
        
        # æ‰¹é‡å¤„ç†æ–‡ä»¶
        results = []
        for i, input_file in enumerate(input_files, 1):
            print(f"\nğŸš€ [{i}/{len(input_files)}] å¼€å§‹å¤„ç†: {os.path.basename(input_file)}")
            
            try:
                result = process_single_file(input_file, args, config, workflow)
                results.append(result)
                print(f"âœ… [{i}/{len(input_files)}] å¤„ç†å®Œæˆ: {os.path.basename(input_file)} ({result['times']['file_total']:.2f}ç§’)")
                
            except Exception as e:
                error_result = {
                    'input_file': input_file,
                    'success': False,
                    'error': str(e)
                }
                results.append(error_result)
                print(f"âŒ [{i}/{len(input_files)}] å¤„ç†å¤±è´¥: {os.path.basename(input_file)} - {e}")
                if args.verbose:
                    import traceback
                    traceback.print_exc()
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        program_total_time = time.time() - program_start_time
        successful_results = [r for r in results if r['success']]
        failed_results = [r for r in results if not r['success']]
        
        # æ±‡æ€»æ‰€æœ‰æˆåŠŸå¤„ç†çš„æ—¶é—´
        if successful_results:
            total_times = {
                'chapter': sum(r['times']['chapter'] for r in successful_results),
                'sentence': sum(r['times']['sentence'] for r in successful_results),
                'audio': sum(r['times']['audio'] for r in successful_results),
                'parse': sum(r['times']['parse'] for r in successful_results),
                'compression': sum(r['times']['compression'] for r in successful_results),
                'vocabulary': sum(r['times']['vocabulary'] for r in successful_results),
                'statistics': sum(r['times']['statistics'] for r in successful_results),
                'total': sum(r['times']['total'] for r in successful_results)
            }
            
            # æ‰“å°æ‰¹é‡å¤„ç†æ±‡æ€»
            print(f"\nğŸ“Š æ‰¹é‡å¤„ç†æ±‡æ€» ({len(successful_results)}/{len(input_files)} æˆåŠŸ):")
            if args.chapter and total_times['total'] > 0:
                print(f"  ç« èŠ‚æ‹†åˆ†: {total_times['chapter']:.2f}ç§’ ({total_times['chapter']/total_times['total']*100:.1f}%)")
            if args.sentence and total_times['total'] > 0:
                print(f"  å¥å­æ‹†åˆ†: {total_times['sentence']:.2f}ç§’ ({total_times['sentence']/total_times['total']*100:.1f}%)")
            if args.audio and total_times['total'] > 0:
                print(f"  éŸ³é¢‘ç”Ÿæˆ: {total_times['audio']:.2f}ç§’ ({total_times['audio']/total_times['total']*100:.1f}%)")
            if args.parse and total_times['total'] > 0:
                print(f"  ç¿»è¯‘å’Œåˆ†æ: {total_times['parse']:.2f}ç§’ ({total_times['parse']/total_times['total']*100:.1f}%)")
            if args.compress and total_times['total'] > 0:
                print(f"  éŸ³é¢‘å‹ç¼©: {total_times['compression']:.2f}ç§’ ({total_times['compression']/total_times['total']*100:.1f}%)")
            if args.vocabulary and total_times['total'] > 0:
                print(f"  è¯æ±‡å¤„ç†: {total_times['vocabulary']:.2f}ç§’ ({total_times['vocabulary']/total_times['total']*100:.1f}%)")
            if args.stats and total_times['statistics'] > 0:
                print(f"  ç»Ÿè®¡æ”¶é›†: {total_times['statistics']:.2f}ç§’ ({total_times['statistics']/total_times['total']*100:.1f}%)")
            print(f"  æ ¸å¿ƒå¤„ç†æ€»è€—æ—¶: {total_times['total']:.2f}ç§’")
            print(f"  ç¨‹åºæ€»è€—æ—¶: {program_total_time:.2f}ç§’")
            
            if args.verbose:
                # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
                total_files = {
                    'sentence_files': sum(r['files']['sentence_files'] for r in successful_results),
                    'audio_files': sum(r['files']['audio_files'] for r in successful_results),
                    'subtitle_files': sum(r['files']['subtitle_files'] for r in successful_results),
                    'compressed_files': sum(r['files']['compressed_files'] for r in successful_results),
                    'parsed_files': sum(r['files']['parsed_files'] for r in successful_results),
                    'chapter_vocab_files': sum(r['files']['chapter_vocab_files'] for r in successful_results)
                }
                
                print(f"\nğŸ“ ç”Ÿæˆæ–‡ä»¶ç»Ÿè®¡:")
                print(f"  ç”Ÿæˆçš„å¥å­æ–‡ä»¶: {total_files['sentence_files']} ä¸ª")
                if args.audio and total_files['audio_files'] > 0:
                    print(f"  ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶: {total_files['audio_files']} ä¸ª")
                    print(f"  ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶: {total_files['subtitle_files']} ä¸ª")
                if args.compress and total_files['compressed_files'] > 0:
                    print(f"  å‹ç¼©çš„éŸ³é¢‘æ–‡ä»¶: {total_files['compressed_files']} ä¸ª")
                if args.parse and total_files['parsed_files'] > 0:
                    print(f"  è§£æçš„å­—å¹•æ–‡ä»¶: {total_files['parsed_files']} ä¸ª")
                if args.vocabulary and total_files['chapter_vocab_files'] > 0:
                    print(f"  ç”Ÿæˆçš„ç« èŠ‚è¯æ±‡æ–‡ä»¶: {total_files['chapter_vocab_files']} ä¸ª")
        
        # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
        if failed_results:
            print(f"\nâŒ å¤±è´¥çš„æ–‡ä»¶ ({len(failed_results)} ä¸ª):")
            for result in failed_results:
                print(f"  â€¢ {os.path.basename(result['input_file'])}: {result['error']}")
        
        # è¿”å›çŠ¶æ€ç 
        return 1 if failed_results else 0
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())