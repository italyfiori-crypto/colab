#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç« èŠ‚æ‹†åˆ†ä¸»ç¨‹åº - ç²¾ç®€ç‰ˆ
æ”¯æŒé…ç½®æ–‡ä»¶å’Œæœ€å°‘çš„å‘½ä»¤è¡Œå‚æ•°
"""

import argparse
import sys
import os
import time

from infra.config_loader import ConfigLoader
from service.workflow_executor import WorkflowExecutor
from util import OUTPUT_DIRECTORIES



def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç« èŠ‚æ‹†åˆ†å·¥å…· - å°†ä¹¦ç±æ–‡æœ¬æ‹†åˆ†ä¸ºç‹¬ç«‹çš„ç« èŠ‚æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s data/greens.txt
  %(prog)s data/book.txt --output-dir ./my_output
  %(prog)s data/book.txt --audio --parse --vocabulary
  %(prog)s data/book.txt --vocabulary --master-vocab ./my_vocab.json
  %(prog)s data/book.txt --config my_config.json --verbose
  
é»˜è®¤é…ç½®æ–‡ä»¶: text_to_audiobook/config.json
é»˜è®¤è¾“å‡ºç›®å½•: ./output
é»˜è®¤æ€»è¯æ±‡è¡¨: script/text_to_audiobook/vocabulary/master_vocabulary.json
è¾“å‡ºæ ¼å¼: chapters/, sub_chapters/, sentences/, audio/, subtitles/, vocabulary/ ç›®å½•
        """
    )
    
    # æ ¸å¿ƒå‚æ•°
    parser.add_argument('input_file',help='è¾“å…¥æ–‡æœ¬æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose','-v',action='store_true',help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    
    # ç« èŠ‚æ‹†åˆ†
    parser.add_argument('--split', action='store_true', help='å¯ç”¨ç« èŠ‚æ‹†åˆ†')

    # éŸ³é¢‘ç”Ÿæˆå‚æ•°
    parser.add_argument('--audio', action='store_true', help='å¯ç”¨éŸ³é¢‘ç”Ÿæˆ')
    parser.add_argument('--voice', default='af_bella', help='è¯­éŸ³æ¨¡å‹ (é»˜è®¤: af_bella)')
    parser.add_argument('--speed', type=float, default=0.8, help='è¯­éŸ³é€Ÿåº¦ (é»˜è®¤: 1.0)')
    
    # å­—å¹•è§£æå‚æ•°
    parser.add_argument('--parse', action='store_true', help='å¯ç”¨å­—å¹•è§£æ')
    
    # éŸ³é¢‘å‹ç¼©å‚æ•°
    parser.add_argument('--compress', action='store_true', help='å¯ç”¨éŸ³é¢‘å‹ç¼©')
    
    # è¯æ±‡å¤„ç†å‚æ•°
    parser.add_argument('--vocabulary', action='store_true', help='å¯ç”¨è¯æ±‡æå–å’Œåˆ†çº§')
    
    # ç»Ÿè®¡å‚æ•°
    parser.add_argument('--stats', action='store_true', help='å¯ç”¨ç»Ÿè®¡ä¿¡æ¯æ”¶é›†')
    args = parser.parse_args()

    # é»˜è®¤ç›®å½•
    program_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    file_name = os.path.basename(args.input_file)
    output_dir = os.path.join(program_root, "output", os.path.splitext(file_name)[0])
    master_vocab_file = os.path.join(program_root, "output", "vocabulary", "master_vocabulary.json")
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')

    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        print(f"é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        return 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    try:
        os.makedirs(output_dir, exist_ok=True)
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {e}")
        return 1
    
    # è®°å½•ç¨‹åºå¼€å§‹æ—¶é—´
    program_start_time = time.time()
    
    try:
        # åŠ è½½é…ç½®
        if not os.path.exists(config_path):
            print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return 1
        
        config_loader = ConfigLoader()
        config = config_loader.load_config(config_path)
        if args.verbose:
            print(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        
        # åˆå§‹åŒ–å·¥ä½œæµæ‰§è¡Œå™¨
        workflow = WorkflowExecutor(config)
        
        # æ‰§è¡Œå„ä¸ªå¤„ç†æµç¨‹
        chapter_files, sub_chapter_files, sentence_files = [], [], []
        chapter_time, sub_chapter_time, sentence_time = 0, 0, 0
        if args.split:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡æœ¬å¤„ç†æµç¨‹
            chapter_files, sub_chapter_files, sentence_files, text_processing_time = workflow.execute_text_processing(args.input_file, output_dir, args.verbose)
            chapter_time = sub_chapter_time = sentence_time = text_processing_time / 3  # å¹³å‡åˆ†é…æ—¶é—´
        else:
            # è·å–å·²å­˜åœ¨çš„æ–‡ä»¶
            from util.file_utils import get_existing_files
            chapter_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['chapters'], ".txt")
            sub_chapter_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['sub_chapters'], ".txt") 
            sentence_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['sentences'], ".txt")
        
        # éŸ³é¢‘ç”Ÿæˆ
        audio_files, subtitle_files, audio_time = [], [], 0
        if args.audio:
            audio_files, subtitle_files, audio_time = workflow.execute_audio_processing(sentence_files, output_dir, args.voice, args.speed, True, args.verbose)
        else:
            from util.file_utils import get_existing_files
            audio_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['audio'], ".wav")
            subtitle_files = get_existing_files(output_dir, OUTPUT_DIRECTORIES['subtitles'], ".srt")

        # å­—å¹•è§£æå’Œç¿»è¯‘
        parsed_files, parse_time = [], 0
        if args.parse:
            parsed_files, parse_time = workflow.execute_translation_and_analysis(subtitle_files, sub_chapter_files, audio_files, output_dir, args.verbose)

        # è¯æ±‡å¤„ç†
        chapter_vocab_files, vocabulary_time = [], 0
        if args.vocabulary:
            book_name = os.path.splitext(os.path.basename(args.input_file))[0]
            chapter_vocab_files, vocabulary_time = workflow.execute_vocabulary_processing(sentence_files, output_dir, book_name, master_vocab_file, args.verbose)
        
        # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
        statistics_time = 0
        if args.stats:
            # ç‹¬ç«‹æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            statistics, statistics_time = workflow.execute_statistics_collection(sub_chapter_files, audio_files, output_dir, args.verbose)
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = chapter_time + sub_chapter_time + sentence_time + audio_time + parse_time + vocabulary_time + statistics_time
        program_total_time = time.time() - program_start_time
        
        # æ‰“å°è€—æ—¶æ±‡æ€»
        print(f"\nğŸ“Š æ‰§è¡Œè€—æ—¶æ±‡æ€»:")
        if args.split:
            print(f"  æ–‡æœ¬å¤„ç†: {chapter_time + sub_chapter_time + sentence_time:.2f}ç§’ ({(chapter_time + sub_chapter_time + sentence_time)/total_time*100:.1f}%)")
        if args.audio:
            print(f"  éŸ³é¢‘ç”Ÿæˆ: {audio_time:.2f}ç§’ ({audio_time/total_time*100:.1f}%)")
        if args.parse:
            print(f"  ç¿»è¯‘å’Œåˆ†æ: {parse_time:.2f}ç§’ ({parse_time/total_time*100:.1f}%)")
        if args.vocabulary:
            print(f"  è¯æ±‡å¤„ç†: {vocabulary_time:.2f}ç§’ ({vocabulary_time/total_time*100:.1f}%)")
        if args.stats and statistics_time > 0:
            print(f"  ç»Ÿè®¡æ”¶é›†: {statistics_time:.2f}ç§’ ({statistics_time/total_time*100:.1f}%)")
        print(f"  æ ¸å¿ƒå¤„ç†æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"  ç¨‹åºæ€»è€—æ—¶: {program_total_time:.2f}ç§’")
        
        if args.verbose:
            # æ˜¾ç¤ºè¾“å‡ºç›®å½•å’Œæ–‡ä»¶ä¿¡æ¯
            print(f"\nè¾“å‡ºç›®å½•: {output_dir}")
            print(f"ç”Ÿæˆçš„å¥å­æ–‡ä»¶: {len(sentence_files)} ä¸ª")
            
            if args.audio and audio_files:
                print(f"ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶: {len(audio_files)} ä¸ª")
                print(f"ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶: {len(subtitle_files)} ä¸ª")
            
            if args.parse and parsed_files:
                print(f"è§£æçš„å­—å¹•æ–‡ä»¶: {len(parsed_files)} ä¸ª")
            
            if args.vocabulary and chapter_vocab_files:
                print(f"ç”Ÿæˆçš„ç« èŠ‚è¯æ±‡æ–‡ä»¶: {len(chapter_vocab_files)} ä¸ª")
        
        return 0
        
    except Exception as e:
        print(f"âŒ æ‹†åˆ†å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())