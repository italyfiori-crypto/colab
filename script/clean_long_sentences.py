#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†è¿‡é•¿å¥å­æ–‡ä»¶è„šæœ¬
åˆ é™¤æ‹†åˆ†å¾—è¿‡é•¿çš„å¥å­æ–‡ä»¶ä»¥åŠå¯¹åº”çš„éŸ³é¢‘ã€è§£æå’Œå­—å¹•æ–‡ä»¶
"""

import os
import argparse
import glob
from typing import List, Tuple, Dict


class LongSentenceCleaner:
    """è¿‡é•¿å¥å­æ–‡ä»¶æ¸…ç†å™¨"""
    
    def __init__(self, max_char_length: int = 200):
        """
        åˆå§‹åŒ–æ¸…ç†å™¨
        
        Args:
            max_char_length: æœ€å¤§å­—ç¬¦é•¿åº¦é˜ˆå€¼
        """
        self.max_char_length = max_char_length
        self.related_dirs = ['audio', 'analysis', 'subtitles']
    
    def validate_book_dir(self, book_dir: str) -> bool:
        """
        éªŒè¯ä¹¦ç±ç›®å½•æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
            
        Returns:
            æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ä¹¦ç±ç›®å½•
        """
        if not os.path.exists(book_dir):
            print(f"âŒ ä¹¦ç±ç›®å½•ä¸å­˜åœ¨: {book_dir}")
            return False
        
        if not os.path.isdir(book_dir):
            print(f"âŒ è·¯å¾„ä¸æ˜¯ç›®å½•: {book_dir}")
            return False
        
        sentences_dir = os.path.join(book_dir, 'sentences')
        if not os.path.exists(sentences_dir):
            print(f"âŒ å¥å­ç›®å½•ä¸å­˜åœ¨: {sentences_dir}")
            return False
        
        return True
    
    def check_sentence_file(self, file_path: str) -> Tuple[bool, int]:
        """
        æ£€æŸ¥å¥å­æ–‡ä»¶æ˜¯å¦è¶…è¿‡é•¿åº¦é˜ˆå€¼
        
        Args:
            file_path: å¥å­æ–‡ä»¶è·¯å¾„
            
        Returns:
            (æ˜¯å¦è¿‡é•¿, æœ€å¤§è¡Œå­—ç¬¦é•¿åº¦)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            max_line_length = 0
            for line_num, line in enumerate(lines, 1):
                # è·³è¿‡æ ‡é¢˜è¡Œã€ç©ºè¡Œã€æ³¨é‡Šè¡Œ
                line = line.strip()
                if not line or line_num == 1 or line.startswith('<!--'):
                    continue
                
                line_length = len(line)
                if line_length > max_line_length:
                    max_line_length = line_length
            
            return max_line_length > self.max_char_length, max_line_length
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False, 0
    
    def find_long_sentence_files(self, book_dir: str) -> List[Tuple[str, int]]:
        """
        æŸ¥æ‰¾ä¹¦ç±ç›®å½•ä¸‹è¿‡é•¿çš„å¥å­æ–‡ä»¶
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
            
        Returns:
            è¿‡é•¿æ–‡ä»¶åˆ—è¡¨: [(æ–‡ä»¶è·¯å¾„, æœ€å¤§å­—ç¬¦é•¿åº¦), ...]
        """
        sentences_dir = os.path.join(book_dir, 'sentences')
        if not os.path.exists(sentences_dir):
            return []
        
        long_files = []
        sentence_files = glob.glob(os.path.join(sentences_dir, '*.txt'))
        
        for file_path in sentence_files:
            is_long, max_length = self.check_sentence_file(file_path)
            if is_long:
                long_files.append((file_path, max_length))
        
        return sorted(long_files, key=lambda x: x[1], reverse=True)
    
    def find_related_files(self, sentence_file: str, book_dir: str) -> List[str]:
        """
        æŸ¥æ‰¾ä¸å¥å­æ–‡ä»¶ç›¸å…³çš„å…¶ä»–æ–‡ä»¶
        
        Args:
            sentence_file: å¥å­æ–‡ä»¶è·¯å¾„
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
            
        Returns:
            ç›¸å…³æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        filename = os.path.basename(sentence_file)
        related_files = []
        
        for dir_name in self.related_dirs:
            dir_path = os.path.join(book_dir, dir_name)
            if os.path.exists(dir_path):
                # æŸ¥æ‰¾åŒåæ–‡ä»¶ï¼ˆå¯èƒ½æœ‰ä¸åŒæ‰©å±•åï¼‰
                base_name = os.path.splitext(filename)[0]
                pattern = os.path.join(dir_path, f"{base_name}.*")
                matched_files = glob.glob(pattern)
                related_files.extend(matched_files)
        
        return related_files
    
    def delete_files(self, files_to_delete: List[str]) -> Dict[str, int]:
        """
        åˆ é™¤æ–‡ä»¶åˆ—è¡¨
        
        Args:
            files_to_delete: è¦åˆ é™¤çš„æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            åˆ é™¤ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {'success': 0, 'failed': 0}
        
        for file_path in files_to_delete:
            try:
                os.remove(file_path)
                stats['success'] += 1
                print(f"ğŸ—‘ï¸  å·²åˆ é™¤: {file_path}")
            except Exception as e:
                stats['failed'] += 1
                print(f"âŒ åˆ é™¤å¤±è´¥ {file_path}: {e}")
        
        return stats
    
    def preview_cleanup(self, book_dir: str) -> None:
        """
        é¢„è§ˆæ¸…ç†æ“ä½œï¼ˆä¸å®é™…åˆ é™¤ï¼‰
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
        """
        print(f"ğŸ” æ‰«æè¿‡é•¿å¥å­æ–‡ä»¶ (æœ€å¤§å­—ç¬¦é•¿åº¦: {self.max_char_length})")
        print(f"ğŸ“‚ ä¹¦ç±ç›®å½•: {book_dir}")
        print("-" * 80)
        
        if not self.validate_book_dir(book_dir):
            return
        
        book_name = os.path.basename(book_dir)
        long_files = self.find_long_sentence_files(book_dir)
        
        if not long_files:
            print(f"ğŸ“­ {book_name}: æœªå‘ç°è¿‡é•¿å¥å­æ–‡ä»¶")
            return
        
        print(f"\nğŸ“š ä¹¦ç±: {book_name}")
        print(f"ğŸ”´ å‘ç° {len(long_files)} ä¸ªè¿‡é•¿å¥å­æ–‡ä»¶:")
        
        total_related = 0
        for sentence_file, max_length in long_files:
            filename = os.path.basename(sentence_file)
            print(f"  â€¢ {filename} (æœ€å¤§è¡Œé•¿åº¦: {max_length} å­—ç¬¦)")
            
            # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
            related_files = self.find_related_files(sentence_file, book_dir)
            if related_files:
                print(f"    å…³è”æ–‡ä»¶:")
                for related_file in related_files:
                    rel_path = os.path.relpath(related_file, book_dir)
                    print(f"      - {rel_path}")
                total_related += len(related_files)
        
        print(f"\nğŸ“Š é¢„è§ˆç»Ÿè®¡:")
        print(f"  ğŸ”´ è¿‡é•¿å¥å­æ–‡ä»¶: {len(long_files)} ä¸ª")
        print(f"  ğŸ”— å…³è”æ–‡ä»¶: {total_related} ä¸ª")
        print(f"  ğŸ“ æ€»è®¡å°†åˆ é™¤: {len(long_files) + total_related} ä¸ªæ–‡ä»¶")
    
    def execute_cleanup(self, book_dir: str) -> None:
        """
        æ‰§è¡Œæ¸…ç†æ“ä½œï¼ˆå®é™…åˆ é™¤æ–‡ä»¶ï¼‰
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
        """
        print(f"ğŸ—‘ï¸  æ‰§è¡Œæ¸…ç†è¿‡é•¿å¥å­æ–‡ä»¶ (æœ€å¤§å­—ç¬¦é•¿åº¦: {self.max_char_length})")
        print(f"ğŸ“‚ ä¹¦ç±ç›®å½•: {book_dir}")
        print("-" * 80)
        
        if not self.validate_book_dir(book_dir):
            return
        
        book_name = os.path.basename(book_dir)
        long_files = self.find_long_sentence_files(book_dir)
        
        if not long_files:
            print(f"ğŸ“­ {book_name}: æœªå‘ç°è¿‡é•¿å¥å­æ–‡ä»¶")
            return
        
        print(f"\nğŸ“š å¤„ç†ä¹¦ç±: {book_name}")
        
        total_stats = {'success': 0, 'failed': 0}
        for sentence_file, max_length in long_files:
            filename = os.path.basename(sentence_file)
            print(f"\nğŸ”´ å¤„ç†è¿‡é•¿æ–‡ä»¶: {filename} (æœ€å¤§è¡Œé•¿åº¦: {max_length} å­—ç¬¦)")
            
            # æ”¶é›†æ‰€æœ‰è¦åˆ é™¤çš„æ–‡ä»¶
            files_to_delete = [sentence_file]
            related_files = self.find_related_files(sentence_file, book_dir)
            files_to_delete.extend(related_files)
            
            # åˆ é™¤æ–‡ä»¶
            stats = self.delete_files(files_to_delete)
            total_stats['success'] += stats['success']
            total_stats['failed'] += stats['failed']
        
        print(f"\nğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸåˆ é™¤: {total_stats['success']} ä¸ªæ–‡ä»¶")
        print(f"  âŒ åˆ é™¤å¤±è´¥: {total_stats['failed']} ä¸ªæ–‡ä»¶")
        print(f"ğŸ‰ æ¸…ç†å®Œæˆ!")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¸…ç†è¿‡é•¿å¥å­æ–‡ä»¶åŠå…¶å…³è”æ–‡ä»¶')
    parser.add_argument('book_dir', help='ä¹¦ç±ç›®å½•è·¯å¾„ï¼ˆå¦‚: output/1812_æ ¼æ—ç«¥è¯_Grimm\'s Fairy Talesï¼‰')
    parser.add_argument('--max-length', type=int, default=200, 
                      help='æœ€å¤§å­—ç¬¦é•¿åº¦é˜ˆå€¼ (é»˜è®¤: 200)')
    parser.add_argument('--delete', action='store_true', 
                      help='å®é™…åˆ é™¤æ–‡ä»¶ï¼ˆé»˜è®¤åªé¢„è§ˆï¼‰')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¸…ç†å™¨
    cleaner = LongSentenceCleaner(max_char_length=args.max_length)
    
    if args.delete:
        # æ‰§è¡Œåˆ é™¤
        print("âš ï¸  è­¦å‘Šï¼šå°†è¦å®é™…åˆ é™¤æ–‡ä»¶ï¼")
        confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/N): ")
        if confirm.lower() in ['y', 'yes']:
            cleaner.execute_cleanup(args.book_dir)
        else:
            print("ğŸš« æ“ä½œå·²å–æ¶ˆ")
    else:
        # é¢„è§ˆæ¨¡å¼
        cleaner.preview_cleanup(args.book_dir)
        print(f"\nğŸ’¡ ä½¿ç”¨ --delete å‚æ•°æ¥å®é™…åˆ é™¤æ–‡ä»¶")


if __name__ == '__main__':
    main()