#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å®¹æ¯”å¯¹è„šæœ¬
æ¯”å¯¹ output ç›®å½•ä¸‹ä¹¦ç±çš„ sentences å’Œ sub_chapters å†…å®¹æ˜¯å¦å¯¹åº”ï¼Œæ£€æµ‹å†…å®¹ç¼ºå¤±
"""

import os
import re
import argparse
import glob
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass


@dataclass
class ComparisonResult:
    """æ¯”å¯¹ç»“æœæ•°æ®ç±»"""
    file_path: str
    is_match: bool
    original_length: int
    processed_length: int
    missing_content: Optional[str] = None
    extra_content: Optional[str] = None
    similarity_percent: float = 0.0


class TextNormalizer:
    """æ–‡æœ¬æ ‡å‡†åŒ–å·¥å…·"""
    
    
    @staticmethod
    def normalize(text: str) -> str:
        """
        æ ‡å‡†åŒ–æ–‡æœ¬ï¼šå»é™¤æ‰€æœ‰ç©ºæ ¼ï¼Œä¸“æ³¨äºå†…å®¹æœ¬èº«
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ ‡å‡†åŒ–åçš„æ–‡æœ¬ï¼ˆæ— ç©ºæ ¼ï¼‰
        """
        if not text:
            return ""
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        text = text.strip()
        
        # å»é™¤æ®µè½é—´çš„å¤šä½™æ¢è¡Œï¼Œä½†ä¿ç•™æ®µè½ç»“æ„
        text = re.sub(r'\n\s*\n', '\n\n', text)
        
        # å…³é”®ç®€åŒ–ï¼šå»é™¤æ‰€æœ‰ç©ºæ ¼å’Œåˆ¶è¡¨ç¬¦
        text = re.sub(r'[ \t]+', '', text)
        
        return text
    
    @staticmethod
    def extract_content_only(text: str) -> str:
        """
        æå–çº¯å†…å®¹ï¼Œå¿½ç•¥æ ‡é¢˜è¡Œ
        
        Args:
            text: åŒ…å«æ ‡é¢˜çš„å®Œæ•´æ–‡æœ¬
            
        Returns:
            å»é™¤æ ‡é¢˜åçš„å†…å®¹æ–‡æœ¬
        """
        lines = text.split('\n')
        if len(lines) <= 2:
            return text
        
        # è·³è¿‡ç¬¬ä¸€è¡Œæ ‡é¢˜å’Œç¬¬äºŒè¡Œç©ºè¡Œ
        content_lines = lines[2:]
        return '\n'.join(content_lines)


class FilePairMatcher:
    """æ–‡ä»¶é…å¯¹å·¥å…·"""
    
    def __init__(self, output_dir: str = "output"):
        self.output_dir = output_dir
    
    def get_book_directories(self) -> List[str]:
        """è·å–æ‰€æœ‰ä¹¦ç±ç›®å½•"""
        book_dirs = []
        if not os.path.exists(self.output_dir):
            return book_dirs
        
        for item in os.listdir(self.output_dir):
            book_path = os.path.join(self.output_dir, item)
            if os.path.isdir(book_path) and not item.startswith('.'):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„å­ç›®å½•
                sub_chapters_dir = os.path.join(book_path, "sub_chapters")
                sentences_dir = os.path.join(book_path, "sentences")
                if os.path.exists(sub_chapters_dir) and os.path.exists(sentences_dir):
                    book_dirs.append(item)
        
        return sorted(book_dirs)
    
    def get_file_pairs(self, book_name: str) -> List[Tuple[str, str]]:
        """
        è·å–æŒ‡å®šä¹¦ç±çš„æ–‡ä»¶é…å¯¹
        
        Args:
            book_name: ä¹¦ç±åç§°
            
        Returns:
            (sub_chapter_file, sentence_file) å…ƒç»„åˆ—è¡¨
        """
        pairs = []
        book_path = os.path.join(self.output_dir, book_name)
        
        sub_chapters_dir = os.path.join(book_path, "sub_chapters")
        sentences_dir = os.path.join(book_path, "sentences")
        
        if not (os.path.exists(sub_chapters_dir) and os.path.exists(sentences_dir)):
            return pairs
        
        # è·å– sub_chapters ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        sub_chapter_files = glob.glob(os.path.join(sub_chapters_dir, "*.txt"))
        
        for sub_chapter_file in sub_chapter_files:
            filename = os.path.basename(sub_chapter_file)
            sentence_file = os.path.join(sentences_dir, filename)
            
            if os.path.exists(sentence_file):
                pairs.append((sub_chapter_file, sentence_file))
        
        return sorted(pairs)


class ContentComparator:
    """å†…å®¹æ¯”å¯¹å·¥å…·"""
    
    def __init__(self):
        self.normalizer = TextNormalizer()
    
    def compare_files(self, sub_chapter_file: str, sentence_file: str) -> ComparisonResult:
        """
        æ¯”å¯¹ä¸¤ä¸ªæ–‡ä»¶çš„å†…å®¹
        
        Args:
            sub_chapter_file: å­ç« èŠ‚æ–‡ä»¶è·¯å¾„
            sentence_file: å¥å­æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ¯”å¯¹ç»“æœ
        """
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(sub_chapter_file, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            with open(sentence_file, 'r', encoding='utf-8') as f:
                processed_content = f.read()
            
            # æå–å®é™…å†…å®¹ï¼ˆå»é™¤æ ‡é¢˜ï¼‰
            original_text = self.normalizer.extract_content_only(original_content)
            processed_text = self.normalizer.extract_content_only(processed_content)
            
            # æ ‡å‡†åŒ–æ–‡æœ¬
            original_normalized = self.normalizer.normalize(original_text)
            processed_normalized = self.normalizer.normalize(processed_text)
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self._calculate_similarity(original_normalized, processed_normalized)
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…
            is_match = original_normalized == processed_normalized
            
            # æŸ¥æ‰¾ç¼ºå¤±æˆ–å¤šä½™çš„å†…å®¹
            missing_content = None
            extra_content = None
            
            if not is_match:
                missing_content = self._find_missing_content(original_normalized, processed_normalized)
                extra_content = self._find_extra_content(original_normalized, processed_normalized)
            
            return ComparisonResult(
                file_path=os.path.basename(sentence_file),
                is_match=is_match,
                original_length=len(original_normalized),
                processed_length=len(processed_normalized),
                missing_content=missing_content,
                extra_content=extra_content,
                similarity_percent=similarity
            )
            
        except Exception as e:
            return ComparisonResult(
                file_path=os.path.basename(sentence_file),
                is_match=False,
                original_length=0,
                processed_length=0,
                missing_content=f"è¯»å–æ–‡ä»¶é”™è¯¯: {str(e)}",
                similarity_percent=0.0
            )
    
    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”"""
        if not text1 and not text2:
            return 100.0
        if not text1 or not text2:
            return 0.0
        
        # å¦‚æœå®Œå…¨ç›¸åŒï¼Œè¿”å›100%
        if text1 == text2:
            return 100.0
        
        # ä½¿ç”¨ç®€å•çš„å­—ç¬¦çº§ç›¸ä¼¼åº¦è®¡ç®—
        max_len = max(len(text1), len(text2))
        
        # è®¡ç®—åŒ¹é…çš„å­—ç¬¦æ•°ï¼ˆå…è®¸ä½ç½®å·®å¼‚ï¼‰
        matching_chars = 0
        text1_chars = list(text1)
        text2_chars = list(text2)
        
        # ç®€å•çš„å­—ç¬¦åŒ¹é…ç»Ÿè®¡
        for char in text1_chars:
            if char in text2_chars:
                text2_chars.remove(char)  # é¿å…é‡å¤è®¡ç®—
                matching_chars += 1
        
        # è®¡ç®—ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”
        similarity = (matching_chars / max_len) * 100
        return min(100.0, max(0.0, similarity))
    
    def _find_missing_content(self, original: str, processed: str) -> Optional[str]:
        """æŸ¥æ‰¾ç¼ºå¤±çš„å†…å®¹"""
        if len(original) <= len(processed):
            return None
        
        # ç®€å•çš„å·®å¼‚æ£€æµ‹
        for i in range(min(len(original), len(processed))):
            if original[i] != processed[i]:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå·®å¼‚ç‚¹ï¼Œè¿”å›å¯èƒ½ç¼ºå¤±çš„å†…å®¹ç‰‡æ®µ
                end_pos = min(i + 100, len(original))  # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                return original[i:end_pos] + "..." if end_pos < len(original) else original[i:end_pos]
        
        # å¦‚æœå‰é¢éƒ½ç›¸åŒï¼Œé‚£ä¹ˆç¼ºå¤±çš„æ˜¯åé¢çš„éƒ¨åˆ†
        return original[len(processed):len(processed)+100] + "..."
    
    def _find_extra_content(self, original: str, processed: str) -> Optional[str]:
        """æŸ¥æ‰¾å¤šä½™çš„å†…å®¹"""
        if len(processed) <= len(original):
            return None
        
        # ç®€å•çš„å¤šä½™å†…å®¹æ£€æµ‹
        for i in range(min(len(original), len(processed))):
            if original[i] != processed[i]:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå·®å¼‚ç‚¹
                end_pos = min(i + 100, len(processed))
                return processed[i:end_pos] + "..." if end_pos < len(processed) else processed[i:end_pos]
        
        # å¤šä½™çš„æ˜¯åé¢çš„éƒ¨åˆ†
        return processed[len(original):len(original)+100] + "..."


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå·¥å…·"""
    
    def __init__(self):
        self.colors = {
            'green': '\033[92m',
            'red': '\033[91m',
            'yellow': '\033[93m',
            'blue': '\033[94m',
            'reset': '\033[0m',
            'bold': '\033[1m'
        }
    
    def _colorize(self, text: str, color: str) -> str:
        """ä¸ºæ–‡æœ¬æ·»åŠ é¢œè‰²"""
        return f"{self.colors.get(color, '')}{text}{self.colors['reset']}"
    
    def print_summary(self, total_files: int, passed_files: int, failed_files: int):
        """æ‰“å°æ€»ç»“ä¿¡æ¯"""
        print(f"\n{self._colorize('=' * 60, 'blue')}")
        print(f"{self._colorize('å†…å®¹æ¯”å¯¹æ€»ç»“', 'bold')}")
        print(f"{self._colorize('=' * 60, 'blue')}")
        print(f"æ€»æ–‡ä»¶æ•°: {self._colorize(str(total_files), 'blue')}")
        print(f"é€šè¿‡æ–‡ä»¶æ•°: {self._colorize(str(passed_files), 'green')}")
        print(f"å¤±è´¥æ–‡ä»¶æ•°: {self._colorize(str(failed_files), 'red')}")
        
        if total_files > 0:
            success_rate = (passed_files / total_files) * 100
            color = 'green' if success_rate >= 95 else 'yellow' if success_rate >= 80 else 'red'
            print(f"æˆåŠŸç‡: {self._colorize(f'{success_rate:.1f}%', color)}")
    
    def print_book_results(self, book_name: str, results: List[ComparisonResult], detailed: bool = False):
        """æ‰“å°å•æœ¬ä¹¦çš„ç»“æœ"""
        passed = sum(1 for r in results if r.is_match)
        failed = len(results) - passed
        
        print(f"\n{self._colorize(f'ğŸ“š {book_name}', 'bold')}")
        print(f"  æ–‡ä»¶æ•°: {len(results)}, é€šè¿‡: {self._colorize(str(passed), 'green')}, å¤±è´¥: {self._colorize(str(failed), 'red')}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
        for result in results:
            if not result.is_match:
                self._print_error_details(result, detailed)
    
    def _print_error_details(self, result: ComparisonResult, detailed: bool):
        """æ‰“å°é”™è¯¯è¯¦æƒ…"""
        print(f"    {self._colorize(result.file_path, 'red')}")
        print(f"     ç›¸ä¼¼åº¦: {result.similarity_percent:.1f}%")
        print(f"     åŸå§‹é•¿åº¦: {result.original_length}, å¤„ç†åé•¿åº¦: {result.processed_length}")
        
        if result.missing_content:
            print(f"     {self._colorize('ç¼ºå¤±å†…å®¹:', 'yellow')} {result.missing_content[:100]}...")
        
        if result.extra_content:
            print(f"     {self._colorize('å¤šä½™å†…å®¹:', 'yellow')} {result.extra_content[:100]}...")
        
        if detailed:
            print()


class ContentValidator:
    """ä¸»è¦çš„å†…å®¹éªŒè¯ç±»"""
    
    def __init__(self, output_dir: str = "output"):
        self.file_matcher = FilePairMatcher(output_dir)
        self.comparator = ContentComparator()
        self.reporter = ReportGenerator()
    
    def validate_book(self, book_name: str, errors_only: bool = False, detailed: bool = False) -> Dict[str, List[ComparisonResult]]:
        """éªŒè¯å•æœ¬ä¹¦ç±"""
        print(f"ğŸ” æ­£åœ¨æ£€æŸ¥ä¹¦ç±: {book_name}")
        
        file_pairs = self.file_matcher.get_file_pairs(book_name)
        if not file_pairs:
            print(f"  âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶å¯¹")
            return {book_name: []}
        
        results = []
        for sub_chapter_file, sentence_file in file_pairs:
            result = self.comparator.compare_files(sub_chapter_file, sentence_file)
            results.append(result)
        
        # åªåœ¨æœ‰é”™è¯¯æˆ–ä¸æ˜¯åªæ˜¾ç¤ºé”™è¯¯æ¨¡å¼æ—¶æ˜¾ç¤ºç»“æœ
        if not errors_only or any(not r.is_match for r in results):
            self.reporter.print_book_results(book_name, results, detailed)
        
        return {book_name: results}
    
    def validate_all(self, book_filter: Optional[str] = None, errors_only: bool = False, detailed: bool = False) -> Dict[str, List[ComparisonResult]]:
        """éªŒè¯æ‰€æœ‰ä¹¦ç±æˆ–æŒ‡å®šä¹¦ç±"""
        books = self.file_matcher.get_book_directories()
        
        if book_filter:
            books = [book for book in books if book_filter.lower() in book.lower()]
        
        if not books:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•ä¹¦ç±ç›®å½•")
            return {}
        
        print(f"ğŸ“– æ‰¾åˆ° {len(books)} æœ¬ä¹¦ç±")
        
        all_results = {}
        total_files = 0
        passed_files = 0
        
        for book_name in books:
            book_results = self.validate_book(book_name, errors_only, detailed)
            all_results.update(book_results)
            
            for results in book_results.values():
                total_files += len(results)
                passed_files += sum(1 for r in results if r.is_match)
        
        failed_files = total_files - passed_files
        self.reporter.print_summary(total_files, passed_files, failed_files)
        
        return all_results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ¯”å¯¹ sentences å’Œ sub_chapters å†…å®¹çš„å®Œæ•´æ€§")
    parser.add_argument("--book", "-b", help="æŒ‡å®šè¦æ£€æŸ¥çš„ä¹¦ç±åç§°ï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰")
    parser.add_argument("--errors-only", "-e", action="store_true", help="åªæ˜¾ç¤ºæœ‰é”™è¯¯çš„æ–‡ä»¶")
    parser.add_argument("--detailed", "-d", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯")
    parser.add_argument("--output-dir", "-o", default="output", help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: outputï¼‰")
    
    args = parser.parse_args()
    
    validator = ContentValidator(args.output_dir)
    validator.validate_all(
        book_filter=args.book,
        errors_only=args.errors_only,
        detailed=args.detailed
    )


if __name__ == "__main__":
    main()