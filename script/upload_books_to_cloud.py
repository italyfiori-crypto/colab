#!/usr/bin/env python3
"""
å¾®ä¿¡äº‘æœåŠ¡ä¹¦ç±æ•°æ®ä¸Šä¼ è„šæœ¬
ç”¨äºå°†outputç›®å½•ä¸‹çš„æœ‰å£°ä¹¦æ•°æ®ä¸Šä¼ åˆ°å¾®ä¿¡äº‘æ•°æ®åº“å’Œå­˜å‚¨
"""

import os
import json
import time
import requests
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from pathlib import Path


class WeChatCloudUploader:
    """å¾®ä¿¡äº‘æœåŠ¡ä¸Šä¼ å™¨"""
    
    def __init__(self, app_id: str, app_secret: str, env_id: str):
        """
        åˆå§‹åŒ–ä¸Šä¼ å™¨
        
        Args:
            app_id: å¾®ä¿¡å°ç¨‹åºAppID
            app_secret: å¾®ä¿¡å°ç¨‹åºAppSecret
            env_id: å¾®ä¿¡äº‘ç¯å¢ƒID
        """
        self.app_id = app_id
        self.app_secret = app_secret
        self.env_id = env_id
        
        # Access Tokenç›¸å…³
        self.access_token = None
        self.token_expires_at = None
        
        # APIç«¯ç‚¹
        self.token_url = "https://api.weixin.qq.com/cgi-bin/token"
        self.upload_file_url = "https://api.weixin.qq.com/tcb/uploadfile"
        self.database_add_url = "https://api.weixin.qq.com/tcb/databaseadd"
        
        # é…ç½®æ—¥å¿—
        self._setup_logging()
        
        # æ•°æ®ç›®å½•
        self.output_dir = Path("output")
        
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # æ–‡ä»¶å¤„ç†å™¨ - è®°å½•æ‰€æœ‰æ—¥å¿—
        file_handler = logging.FileHandler('upload_books.log', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        
        # æ§åˆ¶å°å¤„ç†å™¨ - åªè®°å½•é‡è¦ä¿¡æ¯
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_handler.setFormatter(logging.Formatter('%(message)s'))
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        logging.basicConfig(
            level=logging.INFO,
            handlers=[file_handler, console_handler]
        )
        self.logger = logging.getLogger(__name__)
        
    def get_access_token(self) -> str:
        """
        è·å–Access Token
        
        Returns:
            access_tokenå­—ç¬¦ä¸²
        """
        # æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ
        if (self.access_token and self.token_expires_at and 
            datetime.now() < self.token_expires_at):
            return self.access_token
            
        self.logger.info("æ­£åœ¨è·å–æ–°çš„Access Token...")
        
        params = {
            'grant_type': 'client_credential',
            'appid': self.app_id,
            'secret': self.app_secret
        }
        
        try:
            response = requests.get(self.token_url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if 'access_token' in data:
                self.access_token = data['access_token']
                # æå‰5åˆ†é’Ÿè¿‡æœŸï¼Œé¿å…è¾¹ç•Œæƒ…å†µ
                expires_in = data.get('expires_in', 7200) - 300
                self.token_expires_at = datetime.now() + timedelta(seconds=expires_in)
                
                self.logger.info(f"Access Tokenè·å–æˆåŠŸï¼Œæœ‰æ•ˆæœŸè‡³: {self.token_expires_at}")
                return self.access_token
            else:
                raise Exception(f"è·å–Access Tokenå¤±è´¥: {data}")
                
        except Exception as e:
            self.logger.error(f"è·å–Access Tokenå‡ºé”™: {e}")
            raise
            
    def upload_file(self, local_path: str, cloud_path: str) -> Optional[str]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°äº‘å­˜å‚¨
        
        Args:
            local_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            cloud_path: äº‘å­˜å‚¨è·¯å¾„
            
        Returns:
            ä¸Šä¼ æˆåŠŸè¿”å›file_idï¼Œå¤±è´¥è¿”å›None
        """
        filename = os.path.basename(local_path)
        
        if not os.path.exists(local_path):
            self.logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {local_path}")
            return None
            
        try:
            # 1. è·å–ä¸Šä¼ é“¾æ¥
            access_token = self.get_access_token()
            
            upload_data = {
                "env": self.env_id,
                "path": cloud_path
            }
            
            response = requests.post(
                f"{self.upload_file_url}?access_token={access_token}",
                json=upload_data,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            
            if result.get('errcode') != 0:
                self.logger.error(f"âŒ è·å–ä¸Šä¼ é“¾æ¥å¤±è´¥: {result}")
                return None
            
            # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨
            required_fields = ['url', 'file_id']
            for field in required_fields:
                if field not in result:
                    self.logger.error(f"âŒ APIå“åº”ç¼ºå°‘å¿…è¦å­—æ®µ '{field}': {result}")
                    return None
                    
            upload_url = result['url']
            file_id = result['file_id']
            
            # 2. ä¸Šä¼ æ–‡ä»¶
            # æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼šPOST multipart/form-data
            with open(local_path, 'rb') as f:
                # æ„å»ºPOSTè¡¨å•ï¼Œä¸¥æ ¼æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼
                files = {
                    'key': (None, cloud_path),                              # è¯·æ±‚åŒ…ä¸­çš„ path å­—æ®µ  
                    'Signature': (None, result['authorization']),           # è¿”å›æ•°æ®çš„ authorization å­—æ®µ
                    'x-cos-security-token': (None, result['token']),        # è¿”å›æ•°æ®çš„ token å­—æ®µ
                    'x-cos-meta-fileid': (None, result['cos_file_id']),     # è¿”å›æ•°æ®çš„ cos_file_id å­—æ®µ
                    'file': (os.path.basename(local_path), f)               # æ–‡ä»¶çš„äºŒè¿›åˆ¶å†…å®¹
                }
                
                upload_response = requests.post(upload_url, files=files, timeout=60)
                upload_response.raise_for_status()
            
            self.logger.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {filename}")
            return file_id
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ {os.path.basename(local_path)}: {e}")
            return None
        except KeyError as e:
            self.logger.error(f"âŒ APIå“åº”å­—æ®µç¼ºå¤± {os.path.basename(local_path)}: ç¼ºå°‘å­—æ®µ {e}")
            self.logger.error(f"å®Œæ•´APIå“åº”: {locals().get('result', 'APIå“åº”æœªè·å–')}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥ {os.path.basename(local_path)}: {type(e).__name__}: {e}")
            import traceback
            self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None
            
    def add_database_records(self, collection: str, records: List[Dict]) -> bool:
        """
        æ‰¹é‡æ·»åŠ æ•°æ®åº“è®°å½•
        
        Args:
            collection: é›†åˆåç§°
            records: è®°å½•åˆ—è¡¨
            
        Returns:
            æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        if not records:
            return True
            
        try:
            access_token = self.get_access_token()
            
            # æ„é€ æ•°æ®åº“æŸ¥è¯¢è¯­å¥
            records_str = json.dumps(records, ensure_ascii=False)
            query = f"db.collection('{collection}').add({{data: {records_str}}})"
            
            data = {
                "env": self.env_id,
                "query": query
            }
            
            response = requests.post(
                f"{self.database_add_url}?access_token={access_token}",
                json=data,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            if result.get('errcode') != 0:
                self.logger.error(f"âŒ æ•°æ®åº“æ’å…¥å¤±è´¥: {result}")
                return False
                
            self.logger.info(f"âœ… æˆåŠŸæ’å…¥{len(records)}æ¡è®°å½•åˆ°{collection}é›†åˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            return False
            
    def parse_book_data(self, book_dir: Path) -> Tuple[Dict, List[Dict]]:
        """
        è§£æå•æœ¬ä¹¦çš„æ•°æ®
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•è·¯å¾„
            
        Returns:
            (book_data, chapters_data) å…ƒç»„
        """
        book_id = book_dir.name
        meta_file = book_dir / "meta.json"
        
        if not meta_file.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°meta.jsonæ–‡ä»¶: {meta_file}")
            
        with open(meta_file, 'r', encoding='utf-8') as f:
            meta_data = json.load(f)
            
        book_info = meta_data['book']
        chapters_info = meta_data['chapters']
        
        # æ„é€ booksè¡¨æ•°æ®
        book_data = {
            '_id': book_id,
            'title': book_info['title'],
            'author': book_info.get('author', ''),
            'cover_url': '',  # ç¨åä¸Šä¼ å°é¢åå¡«å……
            'category': book_info.get('category', ''),  # é»˜è®¤æ–‡å­¦ç±»
            'description': book_info.get('description', ''),
            'total_chapters': book_info.get('total_chapters', 0),
            'total_duration': book_info.get('total_duration', 0), 
            'is_active': True,
            'tags': book_info.get('tags', []),
            'local_cover_file': book_info.get('local_cover_file', ''),
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        # æ„é€ chaptersè¡¨æ•°æ®
        chapters_data = []
        
        for i, chapter_info in enumerate(chapters_info):
            chapter_data = {
                '_id': f"{book_id}_{chapter_info['chapter_number']}_{i}",
                'book_id': book_id,
                'chapter_number': chapter_info['chapter_number'],
                'title': chapter_info['title_cn'] or chapter_info['title'],
                'duration': chapter_info['duration'],
                'is_active': True,
                'audio_url': '',  # ç¨åä¸Šä¼ éŸ³é¢‘åå¡«å……
                'subtitle_url': '',  # ç¨åä¸Šä¼ å­—å¹•åå¡«å……
                'local_audio_file': chapter_info.get('local_audio_file', ''),
                'local_subtitle_file': chapter_info.get('local_subtitle_file', ''),
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            chapters_data.append(chapter_data)
            
        return book_data, chapters_data
        
    def upload_book_cover(self, book_dir: Path, book_id: str, book_data: Dict) -> str:
        """
        ä¸Šä¼ ä¹¦ç±å°é¢æ–‡ä»¶
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•
            book_id: ä¹¦ç±ID
            
        Returns:
            cover_file_id
        """
        # ä¸Šä¼ å°é¢
        cover_file = os.path.join(book_dir, book_data.get('local_cover_file', ''))
        if os.path.exists(cover_file):
            cloud_path = f"books/{book_id}/cover.jpg"
            cover_file_id = self.upload_file(str(cover_file), cloud_path)
        else:
            self.logger.warning(f"âš ï¸  å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {cover_file}")
            cover_file_id = ""

        return cover_file_id
        
    def upload_chapter_files(self, book_dir: Path, book_id: str, chapter: Dict) -> Tuple[str, str]:
        """
        ä¸Šä¼ å•ä¸ªç« èŠ‚çš„éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶
        
        Args:
            book_dir: ä¹¦ç±ç›®å½•
            book_id: ä¹¦ç±ID
            chapter: ç« èŠ‚æ•°æ®
            
        Returns:
            (audio_file_id, subtitle_file_id) å…ƒç»„
        """
        audio_file_id = ""
        subtitle_file_id = ""
        
        # ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        audio_file = chapter.get('local_audio_file', '')
        if audio_file and os.path.exists(audio_file):
            audio_filename = os.path.basename(audio_file)
            audio_cloud_path = f"books/{book_id}/audio/{audio_filename}"
            audio_file_id = self.upload_file(audio_file, audio_cloud_path)

        # ä¸Šä¼ å­—å¹•æ–‡ä»¶
        subtitle_file = chapter.get('local_subtitle_file', '')
        if subtitle_file and os.path.exists(subtitle_file):
            subtitle_filename = os.path.basename(subtitle_file)
            subtitle_cloud_path = f"books/{book_id}/subtitles/{subtitle_filename}"
            subtitle_file_id = self.upload_file(subtitle_file, subtitle_cloud_path)

        return audio_file_id, subtitle_file_id
        
    def upload_all_books(self) -> bool:
        """
        ä¸Šä¼ æ‰€æœ‰ä¹¦ç±æ•°æ®
        
        Returns:
            æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        if not self.output_dir.exists():
            self.logger.error(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {self.output_dir}")
            return False
            
        book_dirs = [d for d in self.output_dir.iterdir() 
                    if d.is_dir() and (d / "meta.json").exists()]
                    
        if not book_dirs:
            self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ…å«meta.jsonçš„ä¹¦ç±ç›®å½•")
            return False
            
        self.logger.info(f"ğŸ“š å‘ç°{len(book_dirs)}æœ¬ä¹¦ç±: {[d.name for d in book_dirs]}")
        
        success = True
        
        for book_dir in book_dirs:
            try:
                book_id = book_dir.name
                self.logger.info(f"\nğŸ“– å¤„ç†ä¹¦ç±: {book_id}")
                
                # è§£æä¹¦ç±æ•°æ®
                book_data, chapters_data = self.parse_book_data(book_dir)
                
                # ä¸Šä¼ å°é¢
                cover_file_id = self.upload_book_cover(book_dir, book_id, book_data)
                if cover_file_id:
                    book_data['cover_url'] = cover_file_id
                    
                # å…ˆæ’å…¥ä¹¦ç±æ•°æ®
                self.logger.info(f"ğŸ’¾ æ’å…¥ä¹¦ç±æ•°æ®: {book_data['title']}")
                if not self.add_database_records('books', [book_data]):
                    self.logger.error(f"âŒ ä¹¦ç±æ•°æ®æ’å…¥å¤±è´¥: {book_id}")
                    success = False
                    continue
                
                # é€ä¸ªå¤„ç†ç« èŠ‚ï¼Œä¸Šä¼ æ–‡ä»¶åç«‹å³æ’å…¥æ•°æ®åº“
                for i, chapter in enumerate(chapters_data):
                    try:
                        # ä¸Šä¼ ç« èŠ‚æ–‡ä»¶
                        audio_file_id, subtitle_file_id = self.upload_chapter_files(book_dir, book_id, chapter)
                        
                        # æ›´æ–°ç« èŠ‚æ–‡ä»¶URL
                        if audio_file_id:
                            chapter['audio_url'] = audio_file_id
                        if subtitle_file_id:
                            chapter['subtitle_url'] = subtitle_file_id
                        
                        # æ¸…ç†æœ¬åœ°æ–‡ä»¶è·¯å¾„
                        del chapter['local_audio_file']
                        del chapter['local_subtitle_file']
                        
                        # ç«‹å³æ’å…¥ç« èŠ‚æ•°æ®
                        self.logger.info(f"ğŸ“ æ’å…¥ç« èŠ‚ {i+1}/{len(chapters_data)}: {chapter['title']}")
                        if not self.add_database_records('chapters', [chapter]):
                            self.logger.error(f"âŒ ç« èŠ‚æ•°æ®æ’å…¥å¤±è´¥: {chapter['title']}")
                            success = False
                            continue
                            
                    except Exception as e:
                        self.logger.error(f"âŒ å¤„ç†ç« èŠ‚å¤±è´¥: {chapter.get('title', 'Unknown')} - {e}")
                        success = False
                        continue
                
                # æ¸…ç†ä¹¦ç±æ•°æ®ä¸­çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„
                del book_data['local_cover_file']
                
                self.logger.info(f"âœ… ä¹¦ç±{book_id}å¤„ç†å®Œæˆ")
                
            except Exception as e:
                self.logger.error(f"âŒ å¤„ç†ä¹¦ç±{book_dir.name}å¤±è´¥: {e}")
                import traceback
                self.logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                success = False
                continue
                    
        return success


def main():
    """ä¸»å‡½æ•°"""
    print("å¾®ä¿¡äº‘æœåŠ¡ä¹¦ç±æ•°æ®ä¸Šä¼ è„šæœ¬")
    print("=" * 50)
    print("æ­¤è„šæœ¬å°†æŠŠoutputç›®å½•ä¸‹çš„æœ‰å£°ä¹¦æ•°æ®ä¸Šä¼ åˆ°å¾®ä¿¡äº‘æœåŠ¡")
    print("è¯·ç¡®ä¿å·²ç»åˆ›å»ºäº†bookså’Œchaptersæ•°æ®åº“é›†åˆ")
    print("=" * 50)
    
    # è·å–ç”¨æˆ·è¾“å…¥
    app_id = input("è¯·è¾“å…¥AppID (é»˜è®¤: wx7040936883aa6dad): ").strip() or "wx7040936883aa6dad"
    app_secret = input("è¯·è¾“å…¥AppSecret: ").strip() or "94051e8239a7a5181f32695c3c4895d9"
    env_id = input("è¯·è¾“å…¥äº‘ç¯å¢ƒID: ").strip() or "cloud1-1gpp78j208f0f610"
    
    if not app_secret or not env_id:
        print("é”™è¯¯: AppSecretå’Œäº‘ç¯å¢ƒIDä¸èƒ½ä¸ºç©º")
        return
        
    # ç¡®è®¤æ“ä½œ
    print(f"\né…ç½®ä¿¡æ¯:")
    print(f"AppID: {app_id}")
    print(f"AppSecret: {'*' * len(app_secret)}")
    print(f"äº‘ç¯å¢ƒID: {env_id}")
    
    confirm = input("\nç¡®è®¤å¼€å§‹ä¸Šä¼ ï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("æ“ä½œå·²å–æ¶ˆ")
        return
        
    # åˆ›å»ºä¸Šä¼ å™¨
    uploader = WeChatCloudUploader(app_id, app_secret, env_id)
    
    # æµ‹è¯•è¿æ¥
    try:
        token = uploader.get_access_token()
        print(f"âœ… è¿æ¥æˆåŠŸï¼ŒAccess Token: {token[:20]}...")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return
        
    # å¼€å§‹ä¸Šä¼ 
    print("\nğŸš€ å¼€å§‹ä¸Šä¼ ä¹¦ç±æ•°æ®...")
    start_time = time.time()
    
    try:
        success = uploader.upload_all_books()
        
        elapsed_time = time.time() - start_time
        
        if success:
            print(f"\nğŸ‰ ä¸Šä¼ å®Œæˆï¼è€—æ—¶: {elapsed_time:.2f}ç§’")
            print("ğŸ“‹ è¯·æ£€æŸ¥å¾®ä¿¡äº‘æ§åˆ¶å°ç¡®è®¤æ•°æ®æ˜¯å¦æ­£ç¡®ä¸Šä¼ ")
        else:
            print(f"\nâŒ ä¸Šä¼ è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: upload_books.log")
            
    except Exception as e:
        print(f"\nâŒ ä¸Šä¼ å¤±è´¥: {e}")
        
    print("\nğŸ“ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: upload_books.log")


if __name__ == "__main__":
    main()