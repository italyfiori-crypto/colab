#!/usr/bin/env python3
"""
è¯æ±‡ä¸Šä¼ æœåŠ¡
å¤„ç†è¯æ±‡è¡¨å’Œç« èŠ‚è¯æ±‡å…³è”çš„ä¸Šä¼ é€»è¾‘
"""

import os
import json
import time
import logging
from datetime import datetime
from typing import Dict, List
from pathlib import Path
from wechat_api import WeChatCloudAPI
from data_parser import DataParser


class VocabularyUploader:
    """è¯æ±‡ä¸Šä¼ æœåŠ¡ç±»"""
    
    def __init__(self, api_client: WeChatCloudAPI):
        self.api = api_client
        self.parser = DataParser()
        self.logger = logging.getLogger(__name__)
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        self.program_root = os.path.dirname(os.path.dirname(__file__))
        
        # éŸ³é¢‘ä¸Šä¼ é…ç½®
        self.audio_cloud_path_prefix = "vocabulary/audio/"
        self.audio_format = "wav"  # ä½¿ç”¨AudioGeneratorç”Ÿæˆçš„wavæ ¼å¼
        
    def upload_vocabularies(self, book_dir: Path, book_id: str) -> bool:
        """ä¸Šä¼ å½“å‰ä¹¦ç±çš„è¯æ±‡æ•°æ®å’ŒéŸ³é¢‘æ–‡ä»¶"""
        try:
            # è·å–è¯æ±‡æ€»è¡¨è·¯å¾„
            master_vocab_path = os.path.join(self.program_root, "output", "vocabulary", "master_vocabulary.json")
            
            if not os.path.exists(master_vocab_path):
                self.logger.error(f"è¯æ±‡æ€»è¡¨ä¸å­˜åœ¨: {master_vocab_path}")
                return False
            
            # åŠ è½½æ±‡æ€»è¯å…¸ï¼ˆå·²ç»æ˜¯æ•°æ®åº“æ ¼å¼ï¼‰
            raw_master_vocab = self._load_master_vocabulary(master_vocab_path)
            
            # æ”¶é›†å½“å‰ä¹¦ç±çš„æ‰€æœ‰å•è¯
            book_words = self._collect_book_words(book_dir)
            
            if not book_words:
                self.logger.info("æ²¡æœ‰è¯æ±‡éœ€è¦ä¸Šä¼ ")
                return True
            
            # è¿‡æ»¤å‡ºå½“å‰ä¹¦ç±çš„è¯æ±‡æ•°æ®
            book_vocabulary_data = {word: raw_master_vocab[word] 
                                  for word in book_words 
                                  if word in raw_master_vocab}
            
            if not book_vocabulary_data:
                self.logger.info("æ²¡æœ‰åŒ¹é…çš„è¯æ±‡æ•°æ®")
                return True
            
            # æ‰¾å‡ºéœ€è¦å®Œæ•´å¤„ç†çš„å•è¯ï¼ˆç”¨uploadedåˆ¤æ–­ï¼‰
            words_to_process = [word for word in book_vocabulary_data.keys() 
                              if not book_vocabulary_data[word].get("uploaded")]
            
            if not words_to_process:
                self.logger.info("æ‰€æœ‰è¯æ±‡éƒ½å·²å®Œå…¨å¤„ç†ï¼Œè·³è¿‡ä¸Šä¼ ")
                return True
            
            self.logger.info(f"å¼€å§‹å¤„ç† {len(words_to_process)} ä¸ªè¯æ±‡ï¼ˆæ•°æ®åº“+éŸ³é¢‘ï¼‰...")
            
            success_count = 0
            for idx, word in enumerate(words_to_process):
                try:
                    # è·å–è¯æ±‡æ•°æ®ï¼ˆå·²ç»æ˜¯æ•°æ®åº“æ ¼å¼ï¼‰
                    db_word_data = book_vocabulary_data[word]
                    
                    # æ­¥éª¤1ï¼šä¸Šä¼ è¯æ±‡æ•°æ®åˆ°æ•°æ®åº“
                    db_success = self._insert_word_with_retry(db_word_data)
                    
                    if not db_success:
                        self.logger.error(f"è¯æ±‡æ•°æ®åº“å†™å…¥å¤±è´¥: {word}")
                        continue
                    
                    # æ­¥éª¤2ï¼šä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åˆ°äº‘å­˜å‚¨
                    audio_success, cloud_file_id = self._upload_word_audio(word)
                    
                    if not audio_success:
                        self.logger.error(f"éŸ³é¢‘ä¸Šä¼ å¤±è´¥: {word}")
                        continue
                    
                    # æ­¥éª¤3ï¼šåªæœ‰ä¸¤æ­¥éƒ½æˆåŠŸï¼Œæ‰åœ¨è¯å…¸ä¸­æ ‡è®°å®Œæˆ
                    raw_master_vocab[word]["audio_url"] = cloud_file_id
                    raw_master_vocab[word]["uploaded"] = True
                    
                    success_count += 1
                    self.logger.info(f"å®Œæ•´å¤„ç†æˆåŠŸ: {word}")
                    
                except Exception as e:
                    self.logger.error(f"å¤„ç†è¯æ±‡å¤±è´¥ {word}: {e}")
                    continue
                
                # æ¯10ä¸ªå•è¯æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if (idx + 1) % 10 == 0:
                    self.logger.info(f"ğŸ“ è¿›åº¦: {idx + 1}/{len(words_to_process)}, æˆåŠŸ: {success_count}")
            
            # ä¿å­˜æ›´æ–°çš„è¯æ±‡è¡¨
            if success_count > 0:
                self._save_master_vocabulary(raw_master_vocab, master_vocab_path)
            
            self.logger.info(f"è¯æ±‡å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, æ€»è®¡ {len(book_vocabulary_data)} ä¸ª")
            return True
            
        except Exception as e:
            self.logger.error(f"è¯æ±‡ä¸Šä¼ å¤±è´¥: {e}")
            return False

    def upload_chapter_vocabularies(self, book_dir: Path, book_id: str, vocabulary_data: Dict) -> bool:
        """ä¸Šä¼ ç« èŠ‚è¯æ±‡å…³è”æ•°æ®"""
        try:
            vocab_subchapters_dir = os.path.join(book_dir, "vocabulary")
            if not vocab_subchapters_dir.exists():
                return True
            
            # è·å–å½“å‰ä¹¦ç±çš„å•è¯é¡ºåº
            book_words = self._collect_book_words(book_dir)
            
            # å¤„ç†æ¯ä¸ªå­ç« èŠ‚çš„è¯æ±‡æ–‡ä»¶
            for vocab_file in vocab_subchapters_dir.glob("*.json"):
                try:
                    with open(vocab_file, 'r', encoding='utf-8') as f:
                        vocab_data = json.load(f)
                    
                    subchapter_id = vocab_data.get("subchapter_id", vocab_file.stem)
                    chapter_words = vocab_data.get("words", [])
                    
                    if not chapter_words:
                        continue
                    
                    # æŒ‰ç…§book_wordsçš„é¡ºåºæ’åºç« èŠ‚å•è¯
                    ordered_words = [word for word in book_words if word in chapter_words]
                    
                    chapter_vocab_record = {
                        "_id": f"{book_id}_{subchapter_id}",
                        "book_id": book_id,
                        "chapter_id": subchapter_id,
                        "words": ordered_words,
                        "created_at": datetime.now().isoformat()
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing_record = self.api.query_database('chapter_vocabularies', 
                                                            {'_id': chapter_vocab_record["_id"]}, limit=1)
                    
                    if not existing_record:
                        if not self.api.add_database_records('chapter_vocabularies', [chapter_vocab_record]):
                            self.logger.error(f"ç« èŠ‚è¯æ±‡æ’å…¥å¤±è´¥: {subchapter_id}")
                            return False
                    
                except Exception as e:
                    self.logger.error(f"å¤„ç†ç« èŠ‚è¯æ±‡æ–‡ä»¶å¤±è´¥ {vocab_file}: {e}")
                    continue
            
            return True
            
        except Exception as e:
            self.logger.error(f"ç« èŠ‚è¯æ±‡ä¸Šä¼ å¤±è´¥: {e}")
            return False

    def _collect_book_words(self, book_dir: Path) -> List[str]:
        """æ”¶é›†å½“å‰ä¹¦ç±çš„æ‰€æœ‰å•è¯ï¼ˆæŒ‰é¡ºåºï¼‰"""
        book_words = []
        vocab_subchapters_dir = book_dir / "vocabulary" / "subchapters"
        
        if not vocab_subchapters_dir.exists():
            return book_words
        
        # æŒ‰æ–‡ä»¶åæ’åºå¤„ç†ç« èŠ‚è¯æ±‡
        vocab_files = sorted(vocab_subchapters_dir.glob("*.json"))
        
        for vocab_file in vocab_files:
            try:
                with open(vocab_file, 'r', encoding='utf-8') as f:
                    vocab_data = json.load(f)
                
                chapter_words = vocab_data.get("words", [])
                for word in chapter_words:
                    if word not in book_words:
                        book_words.append(word)
                        
            except Exception as e:
                self.logger.error(f"è¯»å–ç« èŠ‚è¯æ±‡æ–‡ä»¶å¤±è´¥ {vocab_file}: {e}")
                continue
        
        return book_words

    def _insert_word_with_retry(self, word_data: Dict, max_retries: int = 3) -> bool:
        """æ’å…¥å•è¯ï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰"""
        word = word_data['word']
        
        for retry_count in range(max_retries):
            try:
                if self.api.add_database_records('vocabularies', [word_data]):
                    return True
                else:
                    if retry_count < max_retries - 1:
                        time.sleep(1)
                    
            except Exception as e:
                if retry_count < max_retries - 1:
                    time.sleep(2)
                else:
                    self.logger.error(f"å•è¯æ’å…¥å¤±è´¥: {word} - {e}")
                    
        return False

    def _upload_word_audio(self, word: str) -> Tuple[bool, str]:
        """
        ä¸Šä¼ å•ä¸ªè¯æ±‡çš„éŸ³é¢‘æ–‡ä»¶
        
        Args:
            word: å•è¯
            
        Returns:
            (æ˜¯å¦ä¸Šä¼ æˆåŠŸ, äº‘æ–‡ä»¶ID)
        """
        try:
            # è·å–æœ¬åœ°éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_dir = os.path.join(self.program_root, "output", "vocabulary", "compressed_audio")
            audio_file_path = os.path.join(audio_dir, f"{word}.{self.audio_format}")
            
            if not os.path.exists(audio_file_path):
                self.logger.error(f"æœ¬åœ°éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {word}.{self.audio_format}")
                return False, ""
            
            # ä¸Šä¼ åˆ°äº‘å­˜å‚¨
            cloud_path = f"{self.audio_cloud_path_prefix}{word}.{self.audio_format}"
            file_id = self.api.upload_file(audio_file_path, cloud_path)
            
            if file_id:
                return True, file_id
            else:
                return False, ""
                
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘ä¸Šä¼ å¼‚å¸¸ {word}: {e}")
            return False, ""

    def _load_master_vocabulary(self, master_vocab_path: str) -> Dict[str, Dict]:
        """åŠ è½½æ€»è¯æ±‡è¡¨ï¼ˆæ•°æ®åº“æ ¼å¼ï¼‰"""
        if not os.path.exists(master_vocab_path):
            return {}
        
        try:
            vocabulary = {}
            with open(master_vocab_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        word_data = json.loads(line.strip())
                        vocabulary[word_data['word']] = word_data
            return vocabulary
        except Exception as e:
            self.logger.error(f"åŠ è½½æ€»è¯æ±‡è¡¨å¤±è´¥: {e}")
            return {}

    def _save_master_vocabulary(self, vocabulary: Dict[str, Dict], master_vocab_path: str):
        """ä¿å­˜æ€»è¯æ±‡è¡¨ï¼ˆæ•°æ®åº“æ ¼å¼ï¼‰"""
        os.makedirs(os.path.dirname(master_vocab_path), exist_ok=True)
        
        # æŒ‰å•è¯å­—æ¯æ’åº
        sorted_vocab = dict(sorted(vocabulary.items()))
        
        # è¾“å‡ºæ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªå•è¯çš„JSONå­—ç¬¦ä¸²ï¼ˆæ•°æ®åº“æ ¼å¼ï¼‰
        with open(master_vocab_path, 'w', encoding='utf-8') as f:
            for word, word_info in sorted_vocab.items():
                json_line = json.dumps(word_info, ensure_ascii=False, separators=(',', ':'))
                f.write(json_line + '\n')

